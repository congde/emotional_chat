#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒ…ç»ªè¶‹åŠ¿åˆ†æå™¨
æ”¯æŒå¤šç»´åº¦æƒ…ç»ªå»ºæ¨¡ã€è¶‹åŠ¿é¢„æµ‹å’Œå¯è§†åŒ–æ•°æ®ç”Ÿæˆ
"""

import logging
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from backend.database import DatabaseManager, ChatMessage

logger = logging.getLogger(__name__)


class EmotionTrendAnalyzer:
    """
    æƒ…ç»ªè¶‹åŠ¿åˆ†æå™¨
    åˆ†æç”¨æˆ·çš„æƒ…ç»ªå˜åŒ–è¶‹åŠ¿ã€æ¨¡å¼è¯†åˆ«å’Œé£é™©é¢„è­¦
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æƒ…ç»ªè¶‹åŠ¿åˆ†æå™¨"""
        self.db_manager = DatabaseManager()
        logger.info("âœ“ æƒ…ç»ªè¶‹åŠ¿åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_user_emotion_trend(
        self,
        user_id: str,
        days: int = 7,
        include_visualization_data: bool = True
    ) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·çš„æƒ…ç»ªè¶‹åŠ¿
        
        Args:
            user_id: ç”¨æˆ·ID
            days: åˆ†æçš„å¤©æ•°
            include_visualization_data: æ˜¯å¦åŒ…å«å¯è§†åŒ–æ•°æ®
        
        Returns:
            æƒ…ç»ªè¶‹åŠ¿åˆ†æç»“æœ
        """
        try:
            with DatabaseManager() as db:
                # è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ¶ˆæ¯
                start_date = datetime.now() - timedelta(days=days)
                
                messages = db.db.query(ChatMessage)\
                    .filter(ChatMessage.user_id == user_id)\
                    .filter(ChatMessage.role == 'user')\
                    .filter(ChatMessage.created_at >= start_date)\
                    .order_by(ChatMessage.created_at.asc())\
                    .all()
                
                if not messages:
                    return self._empty_trend_result()
                
                # æå–æƒ…ç»ªæ•°æ®
                emotions = []
                intensities = []
                timestamps = []
                
                for msg in messages:
                    if msg.emotion:
                        emotions.append(msg.emotion)
                        intensities.append(msg.emotion_intensity or 5.0)
                        timestamps.append(msg.created_at)
                
                if not emotions:
                    return self._empty_trend_result()
                
                # 1. åŸºç¡€ç»Ÿè®¡
                emotion_distribution = self._calculate_emotion_distribution(emotions)
                dominant_emotion = max(emotion_distribution, key=emotion_distribution.get)
                average_intensity = sum(intensities) / len(intensities)
                
                # 2. è¶‹åŠ¿åˆ†æ
                trend_analysis = self._analyze_trend(emotions, intensities, timestamps)
                
                # 3. æƒ…ç»ªæ³¢åŠ¨åˆ†æ
                volatility = self._calculate_volatility(intensities)
                
                # 4. é£é™©è¯„ä¼°
                risk_assessment = self._assess_risk(
                    emotions,
                    intensities,
                    trend_analysis
                )
                
                # 5. æƒ…ç»ªæ¨¡å¼è¯†åˆ«
                patterns = self._identify_patterns(emotions, timestamps)
                
                # 6. å»ºè®®ç”Ÿæˆ
                recommendations = self._generate_recommendations(
                    dominant_emotion,
                    average_intensity,
                    trend_analysis,
                    risk_assessment
                )
                
                result = {
                    "user_id": user_id,
                    "analysis_period": {
                        "start_date": start_date.isoformat(),
                        "end_date": datetime.now().isoformat(),
                        "days": days
                    },
                    "sample_size": len(emotions),
                    "emotion_distribution": emotion_distribution,
                    "dominant_emotion": dominant_emotion,
                    "average_intensity": round(average_intensity, 2),
                    "trend": trend_analysis,
                    "volatility": volatility,
                    "risk_assessment": risk_assessment,
                    "patterns": patterns,
                    "recommendations": recommendations
                }
                
                # æ·»åŠ å¯è§†åŒ–æ•°æ®
                if include_visualization_data:
                    result["visualization_data"] = self._prepare_visualization_data(
                        emotions,
                        intensities,
                        timestamps
                    )
                
                return result
                
        except Exception as e:
            logger.error(f"æƒ…ç»ªè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return self._empty_trend_result()
    
    def _calculate_emotion_distribution(self, emotions: List[str]) -> Dict[str, float]:
        """è®¡ç®—æƒ…ç»ªåˆ†å¸ƒ"""
        total = len(emotions)
        counts = Counter(emotions)
        return {
            emotion: round(count / total, 3)
            for emotion, count in counts.items()
        }
    
    def _analyze_trend(
        self,
        emotions: List[str],
        intensities: List[float],
        timestamps: List[datetime]
    ) -> Dict[str, Any]:
        """
        åˆ†ææƒ…ç»ªè¶‹åŠ¿
        
        ä½¿ç”¨æ»‘åŠ¨çª—å£æ¯”è¾ƒæ—©æœŸå’Œè¿‘æœŸçš„æƒ…ç»ªçŠ¶æ€
        """
        if len(emotions) < 4:
            return {"trend": "insufficient_data", "direction": "unknown"}
        
        # åˆ†æˆä¸¤åŠï¼šæ—©æœŸ vs è¿‘æœŸ
        mid_point = len(emotions) // 2
        early_emotions = emotions[:mid_point]
        recent_emotions = emotions[mid_point:]
        early_intensities = intensities[:mid_point]
        recent_intensities = intensities[mid_point:]
        
        # è®¡ç®—ææ€§å¾—åˆ†
        def emotion_to_polarity(emotion):
            positive = ["happy", "excited", "grateful"]
            negative = ["sad", "angry", "anxious", "frustrated", "lonely"]
            if emotion in positive:
                return 1
            elif emotion in negative:
                return -1
            return 0
        
        early_polarity = sum(emotion_to_polarity(e) for e in early_emotions) / len(early_emotions)
        recent_polarity = sum(emotion_to_polarity(e) for e in recent_emotions) / len(recent_emotions)
        
        early_avg_intensity = sum(early_intensities) / len(early_intensities)
        recent_avg_intensity = sum(recent_intensities) / len(recent_intensities)
        
        # åˆ¤æ–­è¶‹åŠ¿æ–¹å‘
        polarity_change = recent_polarity - early_polarity
        intensity_change = recent_avg_intensity - early_avg_intensity
        
        if polarity_change > 0.3:
            direction = "improving"
            description = "æƒ…ç»ªçŠ¶æ€å‘ˆæ”¹å–„è¶‹åŠ¿"
        elif polarity_change < -0.3:
            direction = "declining"
            description = "æƒ…ç»ªçŠ¶æ€å‘ˆä¸‹é™è¶‹åŠ¿"
        else:
            direction = "stable"
            description = "æƒ…ç»ªçŠ¶æ€ç›¸å¯¹ç¨³å®š"
        
        return {
            "trend": direction,
            "description": description,
            "polarity_change": round(polarity_change, 3),
            "intensity_change": round(intensity_change, 2),
            "early_polarity": round(early_polarity, 3),
            "recent_polarity": round(recent_polarity, 3)
        }
    
    def _calculate_volatility(self, intensities: List[float]) -> Dict[str, Any]:
        """è®¡ç®—æƒ…ç»ªæ³¢åŠ¨æ€§"""
        if len(intensities) < 2:
            return {"level": "unknown", "score": 0.0}
        
        # è®¡ç®—æ ‡å‡†å·®
        mean = sum(intensities) / len(intensities)
        variance = sum((x - mean) ** 2 for x in intensities) / len(intensities)
        std_dev = variance ** 0.5
        
        # è®¡ç®—ç›¸é‚»ç‚¹çš„å˜åŒ–å¹…åº¦
        changes = [abs(intensities[i] - intensities[i-1]) for i in range(1, len(intensities))]
        avg_change = sum(changes) / len(changes) if changes else 0
        
        # ç»¼åˆè¯„åˆ†
        volatility_score = (std_dev + avg_change) / 2
        
        # åˆ†çº§
        if volatility_score < 1.5:
            level = "low"
            description = "æƒ…ç»ªç›¸å¯¹ç¨³å®š"
        elif volatility_score < 3.0:
            level = "moderate"
            description = "æƒ…ç»ªæœ‰ä¸€å®šæ³¢åŠ¨"
        else:
            level = "high"
            description = "æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§"
        
        return {
            "level": level,
            "score": round(volatility_score, 2),
            "std_dev": round(std_dev, 2),
            "avg_change": round(avg_change, 2),
            "description": description
        }
    
    def _assess_risk(
        self,
        emotions: List[str],
        intensities: List[float],
        trend_analysis: Dict
    ) -> Dict[str, Any]:
        """
        é£é™©è¯„ä¼°
        
        è¯†åˆ«æ½œåœ¨çš„å¿ƒç†å¥åº·é£é™©ä¿¡å·
        """
        risk_level = "low"
        risk_factors = []
        
        # 1. æ£€æŸ¥è´Ÿé¢æƒ…ç»ªæ¯”ä¾‹
        negative_emotions = ["sad", "anxious", "angry", "frustrated", "lonely"]
        negative_count = sum(1 for e in emotions if e in negative_emotions)
        negative_ratio = negative_count / len(emotions)
        
        if negative_ratio > 0.7:
            risk_factors.append("é«˜æ¯”ä¾‹è´Ÿé¢æƒ…ç»ª")
            risk_level = "high"
        elif negative_ratio > 0.5:
            risk_factors.append("è¾ƒå¤šè´Ÿé¢æƒ…ç»ª")
            risk_level = "moderate"
        
        # 2. æ£€æŸ¥é«˜å¼ºåº¦è´Ÿé¢æƒ…ç»ª
        high_intensity_negative = sum(
            1 for e, i in zip(emotions, intensities)
            if e in negative_emotions and i >= 7
        )
        
        if high_intensity_negative >= 3:
            risk_factors.append("å¤šæ¬¡é«˜å¼ºåº¦è´Ÿé¢æƒ…ç»ª")
            risk_level = "high"
        
        # 3. æ£€æŸ¥è¶‹åŠ¿
        if trend_analysis.get("trend") == "declining":
            risk_factors.append("æƒ…ç»ªå‘ˆä¸‹é™è¶‹åŠ¿")
            if risk_level == "low":
                risk_level = "moderate"
        
        # 4. æ£€æŸ¥ç‰¹å®šé«˜é£é™©æƒ…ç»ª
        high_risk_emotions = ["lonely", "anxious"]
        high_risk_count = sum(1 for e in emotions if e in high_risk_emotions)
        
        if high_risk_count > len(emotions) * 0.4:
            risk_factors.append("é¢‘ç¹å‡ºç°ç„¦è™‘/å­¤ç‹¬æƒ…ç»ª")
            risk_level = "high"
        
        # 5. ç”Ÿæˆå»ºè®®
        if risk_level == "high":
            recommendation = "å»ºè®®å…³æ³¨ç”¨æˆ·å¿ƒç†çŠ¶æ€ï¼Œè€ƒè™‘æä¾›ä¸“ä¸šå¿ƒç†æ”¯æŒèµ„æº"
        elif risk_level == "moderate":
            recommendation = "å»ºè®®å¯†åˆ‡å…³æ³¨ï¼Œå¢åŠ å…³æ€€å’Œæ”¯æŒ"
        else:
            recommendation = "æƒ…ç»ªçŠ¶æ€è‰¯å¥½ï¼Œä¿æŒç°æœ‰æ”¯æŒ"
        
        return {
            "level": risk_level,
            "factors": risk_factors,
            "recommendation": recommendation,
            "negative_emotion_ratio": round(negative_ratio, 3)
        }
    
    def _identify_patterns(
        self,
        emotions: List[str],
        timestamps: List[datetime]
    ) -> Dict[str, Any]:
        """
        è¯†åˆ«æƒ…ç»ªæ¨¡å¼
        
        åˆ†ææ—¶é—´æ¨¡å¼ã€å¾ªç¯æ¨¡å¼ç­‰
        """
        patterns = {}
        
        # 1. æ—¶é—´æ®µæ¨¡å¼ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿæ•°æ®ï¼‰
        if len(timestamps) >= 7:
            hour_emotion_map = defaultdict(list)
            for emotion, ts in zip(emotions, timestamps):
                hour_emotion_map[ts.hour].append(emotion)
            
            # æ‰¾å‡ºç‰¹å®šæ—¶é—´æ®µçš„ä¸»å¯¼æƒ…ç»ª
            time_patterns = {}
            for hour, hour_emotions in hour_emotion_map.items():
                if len(hour_emotions) >= 2:
                    most_common = Counter(hour_emotions).most_common(1)[0][0]
                    time_patterns[hour] = most_common
            
            if time_patterns:
                patterns["time_of_day"] = time_patterns
        
        # 2. æƒ…ç»ªåºåˆ—æ¨¡å¼ï¼ˆå¸¸è§çš„æƒ…ç»ªè½¬æ¢ï¼‰
        if len(emotions) >= 5:
            transitions = []
            for i in range(len(emotions) - 1):
                transitions.append(f"{emotions[i]}->{emotions[i+1]}")
            
            common_transitions = Counter(transitions).most_common(3)
            if common_transitions:
                patterns["common_transitions"] = [
                    {"transition": t, "count": c}
                    for t, c in common_transitions
                ]
        
        # 3. å‘¨æœŸæ€§æ¨¡å¼æ£€æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if len(emotions) >= 14:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘¨æœŸæ€§çš„æƒ…ç»ªæ³¢åŠ¨
            # è¿™é‡Œç®€åŒ–ä¸ºæ£€æŸ¥ç›¸åŒæƒ…ç»ªåœ¨ç›¸ä¼¼æ—¶é—´é—´éš”å‡ºç°
            same_emotion_intervals = defaultdict(list)
            
            for emotion in set(emotions):
                indices = [i for i, e in enumerate(emotions) if e == emotion]
                if len(indices) >= 3:
                    intervals = [indices[i+1] - indices[i] for i in range(len(indices)-1)]
                    avg_interval = sum(intervals) / len(intervals)
                    
                    # å¦‚æœé—´éš”ç›¸å¯¹ç¨³å®šï¼Œå¯èƒ½æ˜¯å‘¨æœŸæ€§çš„
                    if max(intervals) - min(intervals) < 3:
                        same_emotion_intervals[emotion] = {
                            "average_interval": round(avg_interval, 1),
                            "occurrences": len(indices)
                        }
            
            if same_emotion_intervals:
                patterns["periodic_emotions"] = dict(same_emotion_intervals)
        
        return patterns if patterns else {"found": False, "message": "æ•°æ®ä¸è¶³ä»¥è¯†åˆ«æ˜æ˜¾æ¨¡å¼"}
    
    def _generate_recommendations(
        self,
        dominant_emotion: str,
        average_intensity: float,
        trend_analysis: Dict,
        risk_assessment: Dict
    ) -> List[str]:
        """ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºé£é™©ç­‰çº§çš„å»ºè®®
        if risk_assessment["level"] == "high":
            recommendations.append("ğŸ”´ é«˜é£é™©è­¦å‘Šï¼šå»ºè®®å°½å¿«è”ç³»ä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆæˆ–æ‹¨æ‰“å¿ƒç†æ´åŠ©çƒ­çº¿ï¼ˆå¸Œæœ›24çƒ­çº¿ï¼š400-161-9995ï¼‰")
        
        # åŸºäºè¶‹åŠ¿çš„å»ºè®®
        if trend_analysis["trend"] == "declining":
            recommendations.append("âš ï¸ æƒ…ç»ªè¶‹åŠ¿ï¼šè¿‘æœŸæƒ…ç»ªå‘ˆä¸‹é™è¶‹åŠ¿ï¼Œå»ºè®®å¢åŠ å…³æ³¨å’Œæ”¯æŒ")
        elif trend_analysis["trend"] == "improving":
            recommendations.append("âœ… ç§¯æè¶‹åŠ¿ï¼šæƒ…ç»ªçŠ¶æ€æŒç»­æ”¹å–„ï¼Œç»§ç»­ä¿æŒï¼")
        
        # åŸºäºä¸»å¯¼æƒ…ç»ªçš„å»ºè®®
        emotion_recommendations = {
            "sad": "å»ºè®®å¢åŠ æ¸©æš–é™ªä¼´ï¼Œæä¾›æƒ…æ„Ÿæ”¯æŒï¼Œé¿å…è¯´æ•™å¼å»ºè®®",
            "anxious": "å»ºè®®æä¾›å¹³é™ç¨³å®šçš„æ”¯æŒï¼Œå¸®åŠ©åˆ†æ­¥éª¤å¤„ç†é—®é¢˜",
            "angry": "å»ºè®®ä¿æŒæ¥çº³æ€åº¦ï¼Œå…ˆå€¾å¬å†å¼•å¯¼",
            "lonely": "å»ºè®®å¼ºåŒ–é™ªä¼´æ„Ÿï¼Œå¤šä½¿ç”¨'æˆ‘åœ¨è¿™é‡Œ'ç±»ä¼¼çš„è¡¨è¾¾",
            "happy": "ç»§ç»­å…±äº«å–œæ‚¦ï¼Œå¯é€‚åº¦å¼•å¯¼è¡¨è¾¾æ›´å¤šç§¯æç»†èŠ‚",
            "frustrated": "å»ºè®®æä¾›æ–°è§†è§’ï¼Œé¿å…ç›´æ¥çš„åŠ±å¿—è¯è¯­"
        }
        
        if dominant_emotion in emotion_recommendations:
            recommendations.append(f"ğŸ’¡ ä¸»å¯¼æƒ…ç»ª({dominant_emotion})å»ºè®®ï¼š{emotion_recommendations[dominant_emotion]}")
        
        # åŸºäºå¼ºåº¦çš„å»ºè®®
        if average_intensity >= 7:
            recommendations.append("âš¡ æƒ…ç»ªå¼ºåº¦è¾ƒé«˜ï¼Œéœ€è¦æ›´å¤šå…³æ³¨å’Œæ·±åº¦å…±æƒ…")
        
        return recommendations if recommendations else ["æƒ…ç»ªçŠ¶æ€ç¨³å®šï¼Œç»§ç»­ä¿æŒæ—¥å¸¸æ”¯æŒ"]
    
    def _prepare_visualization_data(
        self,
        emotions: List[str],
        intensities: List[float],
        timestamps: List[datetime]
    ) -> Dict[str, Any]:
        """
        å‡†å¤‡å¯è§†åŒ–æ•°æ®
        
        è¿”å›é€‚åˆå‰ç«¯å›¾è¡¨å±•ç¤ºçš„æ•°æ®æ ¼å¼
        """
        # 1. æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæƒ…ç»ªå¼ºåº¦æ›²çº¿ï¼‰
        timeline_data = [
            {
                "timestamp": ts.isoformat(),
                "emotion": emotion,
                "intensity": intensity
            }
            for ts, emotion, intensity in zip(timestamps, emotions, intensities)
        ]
        
        # 2. æƒ…ç»ªåˆ†å¸ƒé¥¼å›¾æ•°æ®
        emotion_counts = Counter(emotions)
        pie_chart_data = [
            {"emotion": emotion, "count": count, "percentage": round(count/len(emotions)*100, 1)}
            for emotion, count in emotion_counts.most_common()
        ]
        
        # 3. æ¯æ—¥å¹³å‡å¼ºåº¦ï¼ˆæŸ±çŠ¶å›¾ï¼‰
        daily_intensity = defaultdict(list)
        for ts, intensity in zip(timestamps, intensities):
            date_key = ts.strftime("%Y-%m-%d")
            daily_intensity[date_key].append(intensity)
        
        bar_chart_data = [
            {
                "date": date,
                "average_intensity": round(sum(intensities) / len(intensities), 2),
                "count": len(intensities)
            }
            for date, intensities in sorted(daily_intensity.items())
        ]
        
        # 4. æƒ…ç»ªè½¬æ¢çŸ©é˜µï¼ˆçƒ­åŠ›å›¾ï¼‰
        if len(emotions) >= 2:
            transitions = defaultdict(int)
            for i in range(len(emotions) - 1):
                from_emotion = emotions[i]
                to_emotion = emotions[i + 1]
                transitions[(from_emotion, to_emotion)] += 1
            
            heatmap_data = [
                {
                    "from": from_e,
                    "to": to_e,
                    "count": count
                }
                for (from_e, to_e), count in transitions.items()
            ]
        else:
            heatmap_data = []
        
        return {
            "timeline": timeline_data,
            "pie_chart": pie_chart_data,
            "bar_chart": bar_chart_data,
            "heatmap": heatmap_data
        }
    
    def _empty_trend_result(self) -> Dict[str, Any]:
        """è¿”å›ç©ºç»“æœ"""
        return {
            "user_id": None,
            "analysis_period": None,
            "sample_size": 0,
            "emotion_distribution": {},
            "dominant_emotion": "neutral",
            "average_intensity": 0.0,
            "trend": {"trend": "unknown", "description": "æ•°æ®ä¸è¶³"},
            "volatility": {"level": "unknown", "score": 0.0},
            "risk_assessment": {"level": "unknown", "factors": [], "recommendation": "éœ€è¦æ›´å¤šæ•°æ®"},
            "patterns": {},
            "recommendations": ["éœ€è¦æ›´å¤šäº¤äº’æ•°æ®æ‰èƒ½è¿›è¡Œåˆ†æ"],
            "visualization_data": None
        }
    
    def get_multi_dimensional_emotion_profile(self, user_id: str, days: int = 30) -> Dict[str, Any]:
        """
        è·å–å¤šç»´åº¦æƒ…ç»ªç”»åƒ
        
        ç»¼åˆåˆ†æç”¨æˆ·çš„æƒ…ç»ªç‰¹å¾ï¼Œç”Ÿæˆå®Œæ•´çš„æƒ…ç»ªç”»åƒ
        
        Args:
            user_id: ç”¨æˆ·ID
            days: åˆ†æå¤©æ•°
        
        Returns:
            å¤šç»´åº¦æƒ…ç»ªç”»åƒ
        """
        try:
            # 1. è·å–åŸºç¡€è¶‹åŠ¿åˆ†æ
            trend_result = self.analyze_user_emotion_trend(user_id, days, include_visualization_data=False)
            
            if trend_result["sample_size"] == 0:
                return {"error": "æ•°æ®ä¸è¶³"}
            
            with DatabaseManager() as db:
                start_date = datetime.now() - timedelta(days=days)
                
                messages = db.db.query(ChatMessage)\
                    .filter(ChatMessage.user_id == user_id)\
                    .filter(ChatMessage.role == 'user')\
                    .filter(ChatMessage.created_at >= start_date)\
                    .order_by(ChatMessage.created_at.asc())\
                    .all()
                
                # 2. æƒ…ç»ªç¨³å®šæ€§åˆ†æ
                emotions = [msg.emotion for msg in messages if msg.emotion]
                emotion_changes = sum(1 for i in range(1, len(emotions)) if emotions[i] != emotions[i-1])
                stability_score = 1 - (emotion_changes / len(emotions)) if len(emotions) > 1 else 0.5
                
                # 3. æƒ…ç»ªå¤æ‚åº¦ï¼ˆæœ‰å¤šå°‘ç§ä¸åŒæƒ…ç»ªï¼‰
                unique_emotions = len(set(emotions))
                emotion_complexity = min(unique_emotions / 10, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
                
                # 4. ç§¯ææ€§æŒ‡æ•°
                positive_emotions = ["happy", "excited", "grateful"]
                positive_count = sum(1 for e in emotions if e in positive_emotions)
                positivity_index = positive_count / len(emotions) if emotions else 0
                
                # 5. å‹åŠ›æŒ‡æ•°
                stress_emotions = ["anxious", "frustrated", "angry"]
                stress_count = sum(1 for e in emotions if e in stress_emotions)
                stress_index = stress_count / len(emotions) if emotions else 0
                
                # 6. ç¤¾äº¤æ€§æŒ‡æ ‡ï¼ˆåŸºäºå­¤ç‹¬æƒ…ç»ªï¼‰
                lonely_count = sum(1 for e in emotions if e == "lonely")
                social_connectedness = 1 - (lonely_count / len(emotions)) if emotions else 0.5
                
                # 7. æƒ…ç»ªå¼¹æ€§ï¼ˆä»è´Ÿé¢æƒ…ç»ªæ¢å¤çš„èƒ½åŠ›ï¼‰
                resilience_score = self._calculate_resilience(emotions)
                
                return {
                    "user_id": user_id,
                    "analysis_period_days": days,
                    "sample_size": len(emotions),
                    "dimensions": {
                        "stability": {
                            "score": round(stability_score, 3),
                            "level": "é«˜" if stability_score > 0.7 else "ä¸­" if stability_score > 0.4 else "ä½",
                            "description": "æƒ…ç»ªç¨³å®šæ€§" if stability_score > 0.7 else "æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§"
                        },
                        "complexity": {
                            "score": round(emotion_complexity, 3),
                            "unique_emotions": unique_emotions,
                            "description": "æƒ…ç»ªä½“éªŒä¸°å¯Œ" if emotion_complexity > 0.6 else "æƒ…ç»ªç›¸å¯¹å•ä¸€"
                        },
                        "positivity": {
                            "score": round(positivity_index, 3),
                            "level": "é«˜" if positivity_index > 0.5 else "ä¸­" if positivity_index > 0.3 else "ä½",
                            "description": "ç§¯ææƒ…ç»ªå ä¸»å¯¼" if positivity_index > 0.5 else "éœ€è¦å¢å¼ºç§¯æä½“éªŒ"
                        },
                        "stress": {
                            "score": round(stress_index, 3),
                            "level": "é«˜" if stress_index > 0.4 else "ä¸­" if stress_index > 0.2 else "ä½",
                            "description": "å‹åŠ›æ°´å¹³è¾ƒé«˜" if stress_index > 0.4 else "å‹åŠ›åœ¨å¯æ§èŒƒå›´"
                        },
                        "social_connectedness": {
                            "score": round(social_connectedness, 3),
                            "level": "é«˜" if social_connectedness > 0.7 else "ä¸­" if social_connectedness > 0.5 else "ä½",
                            "description": "ç¤¾äº¤è¿æ¥è‰¯å¥½" if social_connectedness > 0.7 else "å¯èƒ½éœ€è¦æ›´å¤šç¤¾äº¤æ”¯æŒ"
                        },
                        "resilience": {
                            "score": round(resilience_score, 3),
                            "level": "é«˜" if resilience_score > 0.6 else "ä¸­" if resilience_score > 0.4 else "ä½",
                            "description": "æƒ…ç»ªæ¢å¤èƒ½åŠ›å¼º" if resilience_score > 0.6 else "å¯èƒ½éœ€è¦æ”¯æŒæƒ…ç»ªè°ƒèŠ‚"
                        }
                    },
                    "overall_wellbeing_score": round(
                        (stability_score + positivity_index + social_connectedness + resilience_score - stress_index) / 4, 3
                    ),
                    "key_characteristics": self._generate_characteristics(
                        stability_score, positivity_index, stress_index, social_connectedness, resilience_score
                    )
                }
                
        except Exception as e:
            logger.error(f"å¤šç»´åº¦æƒ…ç»ªç”»åƒç”Ÿæˆå¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _calculate_resilience(self, emotions: List[str]) -> float:
        """
        è®¡ç®—æƒ…ç»ªå¼¹æ€§ï¼ˆä»è´Ÿé¢æƒ…ç»ªæ¢å¤çš„èƒ½åŠ›ï¼‰
        
        æ£€æµ‹ä»è´Ÿé¢æƒ…ç»ªåˆ°æ­£é¢æƒ…ç»ªçš„è½¬æ¢æ¯”ä¾‹
        """
        if len(emotions) < 2:
            return 0.5
        
        negative_emotions = ["sad", "angry", "anxious", "frustrated", "lonely"]
        positive_emotions = ["happy", "excited", "grateful"]
        
        recovery_count = 0
        negative_to_negative = 0
        
        for i in range(len(emotions) - 1):
            if emotions[i] in negative_emotions:
                if emotions[i + 1] in positive_emotions or emotions[i + 1] == "neutral":
                    recovery_count += 1
                elif emotions[i + 1] in negative_emotions:
                    negative_to_negative += 1
        
        total_negative_episodes = recovery_count + negative_to_negative
        
        if total_negative_episodes == 0:
            return 0.8  # æ²¡æœ‰è´Ÿé¢æƒ…ç»ªï¼Œå¼¹æ€§é»˜è®¤è¾ƒé«˜
        
        return recovery_count / total_negative_episodes
    
    def _generate_characteristics(
        self,
        stability: float,
        positivity: float,
        stress: float,
        social: float,
        resilience: float
    ) -> List[str]:
        """ç”Ÿæˆå…³é”®ç‰¹å¾æè¿°"""
        characteristics = []
        
        if stability > 0.7:
            characteristics.append("æƒ…ç»ªç¨³å®š")
        elif stability < 0.4:
            characteristics.append("æƒ…ç»ªæ³¢åŠ¨è¾ƒå¤§")
        
        if positivity > 0.5:
            characteristics.append("ä¹è§‚ç§¯æ")
        elif positivity < 0.3:
            characteristics.append("éœ€è¦ç§¯ææƒ…ç»ªæ”¯æŒ")
        
        if stress > 0.4:
            characteristics.append("å‹åŠ›è¾ƒé«˜")
        
        if social < 0.5:
            characteristics.append("å¯èƒ½éœ€è¦ç¤¾äº¤è¿æ¥")
        
        if resilience > 0.6:
            characteristics.append("æƒ…ç»ªæ¢å¤èƒ½åŠ›å¼º")
        elif resilience < 0.4:
            characteristics.append("éœ€è¦æƒ…ç»ªè°ƒèŠ‚æ”¯æŒ")
        
        return characteristics if characteristics else ["æƒ…ç»ªçŠ¶æ€å¹³è¡¡"]


# ä¾¿æ·å‡½æ•°
def analyze_emotion_trend(user_id: str, days: int = 7) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æç”¨æˆ·æƒ…ç»ªè¶‹åŠ¿
    
    Args:
        user_id: ç”¨æˆ·ID
        days: å¤©æ•°
    
    Returns:
        è¶‹åŠ¿åˆ†æç»“æœ
    """
    analyzer = EmotionTrendAnalyzer()
    return analyzer.analyze_user_emotion_trend(user_id, days)


def get_emotion_profile(user_id: str, days: int = 30) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–å¤šç»´åº¦æƒ…ç»ªç”»åƒ
    
    Args:
        user_id: ç”¨æˆ·ID
        days: å¤©æ•°
    
    Returns:
        æƒ…ç»ªç”»åƒ
    """
    analyzer = EmotionTrendAnalyzer()
    return analyzer.get_multi_dimensional_emotion_profile(user_id, days)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # éœ€è¦å®é™…çš„æ•°æ®åº“æ•°æ®æ‰èƒ½æµ‹è¯•
    print("æƒ…ç»ªè¶‹åŠ¿åˆ†æå™¨å·²å°±ç»ª")
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("  analyzer = EmotionTrendAnalyzer()")
    print("  trend = analyzer.analyze_user_emotion_trend('user_123', days=7)")
    print("  profile = analyzer.get_multi_dimensional_emotion_profile('user_123', days=30)")

