#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨æˆ·åé¦ˆåˆ†æå·¥å…·
åˆ†æç”¨æˆ·åé¦ˆï¼Œè¯†åˆ«å¸¸è§é—®é¢˜ï¼Œç”Ÿæˆæ”¹è¿›å»ºè®®
"""

import json
from typing import List, Dict, Any
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from backend.database import DatabaseManager


class FeedbackAnalyzer:
    """åé¦ˆåˆ†æå™¨"""
    
    def __init__(self):
        self.db_manager = DatabaseManager()
    
    def analyze_all_feedback(self, days: int = 30) -> Dict[str, Any]:
        """
        åˆ†ææ‰€æœ‰åé¦ˆæ•°æ®
        
        Args:
            days: åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        # è·å–æ‰€æœ‰åé¦ˆ
        all_feedbacks = self.db_manager.get_all_feedback(limit=10000)
        
        # è¿‡æ»¤æ—¶é—´èŒƒå›´
        cutoff_date = datetime.now() - timedelta(days=days)
        feedbacks = [f for f in all_feedbacks if f.created_at >= cutoff_date]
        
        if not feedbacks:
            return {
                "status": "no_data",
                "message": "æ²¡æœ‰æ‰¾åˆ°åé¦ˆæ•°æ®"
            }
        
        # åŸºç¡€ç»Ÿè®¡
        total_count = len(feedbacks)
        avg_rating = sum(f.rating for f in feedbacks) / total_count if total_count > 0 else 0
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        type_counter = Counter(f.feedback_type for f in feedbacks)
        
        # æŒ‰è¯„åˆ†åˆ†ç»„
        rating_distribution = Counter(f.rating for f in feedbacks)
        
        # è¯†åˆ«é—®é¢˜ä¸¥é‡ç¨‹åº¦
        problem_severity = {
            'critical': [],  # ä¸¥é‡é—®é¢˜ï¼ˆè¯„åˆ†1-2ï¼‰
            'moderate': [],  # ä¸­ç­‰é—®é¢˜ï¼ˆè¯„åˆ†3ï¼‰
            'minor': []      # è½»å¾®é—®é¢˜ï¼ˆè¯„åˆ†4-5ä½†æœ‰è´Ÿé¢åé¦ˆï¼‰
        }
        
        for feedback in feedbacks:
            if feedback.rating <= 2:
                problem_severity['critical'].append(feedback)
            elif feedback.rating == 3:
                problem_severity['moderate'].append(feedback)
            elif feedback.rating >= 4 and feedback.feedback_type in ['irrelevant', 'lack_empathy', 'overstepping']:
                problem_severity['minor'].append(feedback)
        
        # åˆ†æå„ç±»é—®é¢˜
        problem_analysis = {
            'irrelevant': self._analyze_irrelevant_issues(
                [f for f in feedbacks if f.feedback_type == 'irrelevant']
            ),
            'lack_empathy': self._analyze_empathy_issues(
                [f for f in feedbacks if f.feedback_type == 'lack_empathy']
            ),
            'overstepping': self._analyze_overstepping_issues(
                [f for f in feedbacks if f.feedback_type == 'overstepping']
            )
        }
        
        # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
        report = {
            "analysis_date": datetime.now().isoformat(),
            "days_analyzed": days,
            "total_feedbacks": total_count,
            "average_rating": round(avg_rating, 2),
            "feedback_by_type": dict(type_counter),
            "rating_distribution": dict(rating_distribution),
            "problem_severity": {
                "critical_count": len(problem_severity['critical']),
                "moderate_count": len(problem_severity['moderate']),
                "minor_count": len(problem_severity['minor'])
            },
            "problem_analysis": problem_analysis,
            "recommendations": self._generate_recommendations(problem_analysis, type_counter)
        }
        
        return report
    
    def _analyze_irrelevant_issues(self, feedbacks: List) -> Dict[str, Any]:
        """åˆ†æç­”éæ‰€é—®çš„é—®é¢˜"""
        if not feedbacks:
            return {"count": 0, "examples": [], "patterns": []}
        
        patterns = []
        examples = []
        
        for feedback in feedbacks[:10]:  # å–å‰10ä¸ªç¤ºä¾‹
            examples.append({
                "user_message": feedback.user_message[:100] if feedback.user_message else "",
                "bot_response": feedback.bot_response[:100] if feedback.bot_response else "",
                "comment": feedback.comment[:100] if feedback.comment else "",
                "rating": feedback.rating
            })
        
        # è¯†åˆ«å¸¸è§æ¨¡å¼
        keywords_in_comments = []
        for f in feedbacks:
            if f.comment:
                keywords_in_comments.extend(self._extract_keywords(f.comment))
        
        keyword_counter = Counter(keywords_in_comments)
        patterns = [
            {"keyword": k, "frequency": v} 
            for k, v in keyword_counter.most_common(10)
        ]
        
        return {
            "count": len(feedbacks),
            "average_rating": round(sum(f.rating for f in feedbacks) / len(feedbacks), 2),
            "examples": examples,
            "patterns": patterns,
            "severity": "high" if len(feedbacks) > 10 else "medium" if len(feedbacks) > 5 else "low"
        }
    
    def _analyze_empathy_issues(self, feedbacks: List) -> Dict[str, Any]:
        """åˆ†æç¼ºä¹å…±æƒ…çš„é—®é¢˜"""
        if not feedbacks:
            return {"count": 0, "examples": [], "patterns": []}
        
        examples = []
        for feedback in feedbacks[:10]:
            examples.append({
                "user_message": feedback.user_message[:100] if feedback.user_message else "",
                "bot_response": feedback.bot_response[:100] if feedback.bot_response else "",
                "comment": feedback.comment[:100] if feedback.comment else "",
                "rating": feedback.rating
            })
        
        # è¯†åˆ«ç¼ºä¹å…±æƒ…çš„æ¨¡å¼
        empathy_keywords = ['å†·æ¼ ', 'æœºæ¢°', 'æ²¡æœ‰æ„Ÿæƒ…', 'ä¸ç†è§£', 'æ•·è¡', 'å¥—è¯']
        pattern_matches = defaultdict(int)
        
        for f in feedbacks:
            if f.comment:
                for keyword in empathy_keywords:
                    if keyword in f.comment:
                        pattern_matches[keyword] += 1
        
        patterns = [
            {"keyword": k, "frequency": v} 
            for k, v in sorted(pattern_matches.items(), key=lambda x: x[1], reverse=True)
        ]
        
        return {
            "count": len(feedbacks),
            "average_rating": round(sum(f.rating for f in feedbacks) / len(feedbacks), 2),
            "examples": examples,
            "patterns": patterns,
            "severity": "high" if len(feedbacks) > 10 else "medium" if len(feedbacks) > 5 else "low"
        }
    
    def _analyze_overstepping_issues(self, feedbacks: List) -> Dict[str, Any]:
        """åˆ†æè¶Šç•Œæä¾›å»ºè®®çš„é—®é¢˜"""
        if not feedbacks:
            return {"count": 0, "examples": [], "patterns": []}
        
        examples = []
        for feedback in feedbacks[:10]:
            examples.append({
                "user_message": feedback.user_message[:100] if feedback.user_message else "",
                "bot_response": feedback.bot_response[:100] if feedback.bot_response else "",
                "comment": feedback.comment[:100] if feedback.comment else "",
                "rating": feedback.rating
            })
        
        # è¯†åˆ«è¶Šç•Œå»ºè®®çš„æ¨¡å¼
        overstepping_keywords = ['åº”è¯¥', 'å¿…é¡»', 'å»ºè®®ä½ ', 'ä½ åº”è¯¥', 'æœ€å¥½', 'ç›´æ¥å»ºè®®', 'å‘½ä»¤', 'æŒ‡å¯¼']
        pattern_matches = defaultdict(int)
        
        for f in feedbacks:
            if f.bot_response:
                for keyword in overstepping_keywords:
                    if keyword in f.bot_response:
                        pattern_matches[keyword] += 1
        
        patterns = [
            {"keyword": k, "frequency": v} 
            for k, v in sorted(pattern_matches.items(), key=lambda x: x[1], reverse=True)
        ]
        
        return {
            "count": len(feedbacks),
            "average_rating": round(sum(f.rating for f in feedbacks) / len(feedbacks), 2),
            "examples": examples,
            "patterns": patterns,
            "severity": "high" if len(feedbacks) > 10 else "medium" if len(feedbacks) > 5 else "low"
        }
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼Œå¯ä»¥åç»­ä¼˜åŒ–ä¸ºä½¿ç”¨NLPå·¥å…·
        common_words = ['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'è¿™', 'é‚£', 'å°±', 'ä¸', 'å¾ˆ', 'å¤ª']
        words = [w for w in text.split() if len(w) > 1 and w not in common_words]
        return words[:5]  # è¿”å›å‰5ä¸ªå…³é”®è¯
    
    def _generate_recommendations(self, problem_analysis: Dict, type_counter: Counter) -> List[Dict[str, str]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # é’ˆå¯¹ç­”éæ‰€é—®çš„å»ºè®®
        if problem_analysis['irrelevant']['count'] > 5:
            severity = problem_analysis['irrelevant']['severity']
            recommendations.append({
                "issue": "ç­”éæ‰€é—®",
                "severity": severity,
                "priority": "high" if severity == "high" else "medium",
                "recommendation": "å¢å¼ºä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼Œç¡®ä¿å›å¤ä¸ç”¨æˆ·é—®é¢˜ç›´æ¥ç›¸å…³ã€‚å»ºè®®åœ¨Promptä¸­å¢åŠ 'è¯·ç›´æ¥å›åº”ç”¨æˆ·çš„é—®é¢˜ï¼Œé¿å…ç­”éæ‰€é—®'çš„æŒ‡ä»¤ã€‚",
                "action_items": [
                    "æ£€æŸ¥å¯¹è¯å†å²çš„ä½¿ç”¨æ˜¯å¦å……åˆ†",
                    "å¢åŠ æ›´å¤šç›¸å…³æ€§æ£€æŸ¥çš„ç¤ºä¾‹",
                    "è°ƒæ•´Promptä¸­çš„å“åº”æ ¼å¼è¦æ±‚"
                ]
            })
        
        # é’ˆå¯¹ç¼ºä¹å…±æƒ…çš„å»ºè®®
        if problem_analysis['lack_empathy']['count'] > 5:
            severity = problem_analysis['lack_empathy']['severity']
            recommendations.append({
                "issue": "ç¼ºä¹å…±æƒ…",
                "severity": severity,
                "priority": "high",
                "recommendation": "å¼ºåŒ–æƒ…æ„Ÿè¯†åˆ«å’Œå…±æƒ…è¡¨è¾¾ã€‚åœ¨Promptä¸­å¢åŠ æ›´å¤šæƒ…æ„Ÿå…±é¸£çš„ç¤ºä¾‹ï¼Œè¦æ±‚å…ˆè¯†åˆ«æƒ…ç»ªï¼Œå†è¡¨è¾¾ç†è§£ã€‚",
                "action_items": [
                    "åœ¨ç³»ç»ŸPromptä¸­å¼ºè°ƒå…±æƒ…çš„é‡è¦æ€§",
                    "å¢åŠ æƒ…æ„Ÿè¯†åˆ«å’Œå›åº”çš„ç¤ºä¾‹",
                    "ä½¿ç”¨æ›´æ¸©æš–ã€æ›´äººæ€§åŒ–çš„è¯­è¨€",
                    "é¿å…ä½¿ç”¨æœºæ¢°åŒ–çš„å¥—è¯"
                ]
            })
        
        # é’ˆå¯¹è¶Šç•Œå»ºè®®çš„å»ºè®®
        if problem_analysis['overstepping']['count'] > 5:
            severity = problem_analysis['overstepping']['severity']
            recommendations.append({
                "issue": "è¶Šç•Œæä¾›å»ºè®®",
                "severity": severity,
                "priority": "medium",
                "recommendation": "æ˜ç¡®è§’è‰²å®šä½ï¼Œé¿å…æä¾›ä¸“ä¸šå»ºè®®ã€‚åœ¨Promptä¸­å¼ºè°ƒ'åªå€¾å¬å’Œé™ªä¼´ï¼Œä¸æä¾›å…·ä½“å»ºè®®'çš„åŸåˆ™ã€‚",
                "action_items": [
                    "ä¿®æ”¹Promptä¸­çš„ç¦æ­¢è¡Œä¸ºæ¸…å•",
                    "å¢åŠ è¾¹ç•Œç¤ºä¾‹ï¼ˆä»€ä¹ˆå¯ä»¥è¯´ï¼Œä»€ä¹ˆä¸èƒ½è¯´ï¼‰",
                    "å‡å°‘ä½¿ç”¨'åº”è¯¥'ã€'å»ºè®®'ç­‰æŒ‡å¯¼æ€§è¯æ±‡",
                    "å½“ç”¨æˆ·å¯»æ±‚å»ºè®®æ—¶ï¼Œå¼•å¯¼å…¶å¯»æ±‚ä¸“ä¸šå¸®åŠ©"
                ]
            })
        
        # å¦‚æœæ•´ä½“è¯„åˆ†åä½
        total_feedbacks = sum(type_counter.values())
        negative_feedbacks = sum(count for ftype, count in type_counter.items() 
                                 if ftype in ['irrelevant', 'lack_empathy', 'overstepping'])
        
        if total_feedbacks > 0 and negative_feedbacks / total_feedbacks > 0.3:
            recommendations.append({
                "issue": "æ•´ä½“æ»¡æ„åº¦è¾ƒä½",
                "severity": "high",
                "priority": "high",
                "recommendation": "éœ€è¦è¿›è¡Œå…¨é¢çš„Promptä¼˜åŒ–ã€‚è€ƒè™‘é‡æ–°è®¾è®¡ç³»ç»Ÿè§’è‰²å®šä½å’Œè¡Œä¸ºå‡†åˆ™ã€‚",
                "action_items": [
                    "æ”¶é›†æ›´å¤šç”¨æˆ·æœŸæœ›çš„åé¦ˆ",
                    "è¿›è¡ŒA/Bæµ‹è¯•å¯¹æ¯”ä¸åŒPromptçš„æ•ˆæœ",
                    "é‚€è¯·å¿ƒç†å­¦ä¸“å®¶å®¡æ ¸Promptè®¾è®¡",
                    "å¢åŠ æ›´å¤šæ­£é¢ç¤ºä¾‹"
                ]
            })
        
        return recommendations
    
    def generate_detailed_report(self, output_file: str = None) -> str:
        """
        ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        analysis = self.analyze_all_feedback()
        
        report_lines = [
            "=" * 80,
            "ç”¨æˆ·åé¦ˆåˆ†ææŠ¥å‘Š",
            "=" * 80,
            f"\nç”Ÿæˆæ—¶é—´: {analysis.get('analysis_date', 'N/A')}",
            f"åˆ†æå‘¨æœŸ: æœ€è¿‘ {analysis.get('days_analyzed', 'N/A')} å¤©",
            f"\næ€»åé¦ˆæ•°: {analysis.get('total_feedbacks', 0)}",
            f"å¹³å‡è¯„åˆ†: {analysis.get('average_rating', 0)}/5.0",
            "\n" + "=" * 80,
            "\n## åé¦ˆç±»å‹åˆ†å¸ƒ",
            "-" * 80
        ]
        
        # åé¦ˆç±»å‹åˆ†å¸ƒ
        feedback_by_type = analysis.get('feedback_by_type', {})
        for ftype, count in feedback_by_type.items():
            percentage = (count / analysis['total_feedbacks'] * 100) if analysis['total_feedbacks'] > 0 else 0
            report_lines.append(f"{ftype:20s}: {count:5d} ({percentage:5.1f}%)")
        
        # è¯„åˆ†åˆ†å¸ƒ
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## è¯„åˆ†åˆ†å¸ƒ",
            "-" * 80
        ])
        rating_dist = analysis.get('rating_distribution', {})
        for rating in sorted(rating_dist.keys()):
            count = rating_dist[rating]
            percentage = (count / analysis['total_feedbacks'] * 100) if analysis['total_feedbacks'] > 0 else 0
            stars = "â˜…" * rating + "â˜†" * (5 - rating)
            report_lines.append(f"{stars:20s}: {count:5d} ({percentage:5.1f}%)")
        
        # é—®é¢˜ä¸¥é‡ç¨‹åº¦
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## é—®é¢˜ä¸¥é‡ç¨‹åº¦",
            "-" * 80
        ])
        problem_severity = analysis.get('problem_severity', {})
        report_lines.append(f"ä¸¥é‡é—®é¢˜ (è¯„åˆ†1-2):  {problem_severity.get('critical_count', 0)}")
        report_lines.append(f"ä¸­ç­‰é—®é¢˜ (è¯„åˆ†3):    {problem_severity.get('moderate_count', 0)}")
        report_lines.append(f"è½»å¾®é—®é¢˜ (è¯„åˆ†4-5):  {problem_severity.get('minor_count', 0)}")
        
        # é—®é¢˜è¯¦ç»†åˆ†æ
        problem_analysis = analysis.get('problem_analysis', {})
        
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## ç­”éæ‰€é—®é—®é¢˜åˆ†æ",
            "-" * 80
        ])
        irrelevant = problem_analysis.get('irrelevant', {})
        report_lines.append(f"é—®é¢˜æ•°é‡: {irrelevant.get('count', 0)}")
        report_lines.append(f"å¹³å‡è¯„åˆ†: {irrelevant.get('average_rating', 0)}")
        report_lines.append(f"ä¸¥é‡ç¨‹åº¦: {irrelevant.get('severity', 'N/A')}")
        
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## ç¼ºä¹å…±æƒ…é—®é¢˜åˆ†æ",
            "-" * 80
        ])
        lack_empathy = problem_analysis.get('lack_empathy', {})
        report_lines.append(f"é—®é¢˜æ•°é‡: {lack_empathy.get('count', 0)}")
        report_lines.append(f"å¹³å‡è¯„åˆ†: {lack_empathy.get('average_rating', 0)}")
        report_lines.append(f"ä¸¥é‡ç¨‹åº¦: {lack_empathy.get('severity', 'N/A')}")
        
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## è¶Šç•Œå»ºè®®é—®é¢˜åˆ†æ",
            "-" * 80
        ])
        overstepping = problem_analysis.get('overstepping', {})
        report_lines.append(f"é—®é¢˜æ•°é‡: {overstepping.get('count', 0)}")
        report_lines.append(f"å¹³å‡è¯„åˆ†: {overstepping.get('average_rating', 0)}")
        report_lines.append(f"ä¸¥é‡ç¨‹åº¦: {overstepping.get('severity', 'N/A')}")
        
        # æ”¹è¿›å»ºè®®
        report_lines.extend([
            "\n" + "=" * 80,
            "\n## æ”¹è¿›å»ºè®®",
            "=" * 80
        ])
        
        recommendations = analysis.get('recommendations', [])
        for i, rec in enumerate(recommendations, 1):
            report_lines.extend([
                f"\n### å»ºè®® {i}: {rec.get('issue', 'N/A')}",
                f"ä¸¥é‡ç¨‹åº¦: {rec.get('severity', 'N/A')}",
                f"ä¼˜å…ˆçº§: {rec.get('priority', 'N/A')}",
                f"\nå»ºè®®å†…å®¹:",
                rec.get('recommendation', 'N/A'),
                f"\nè¡ŒåŠ¨é¡¹:"
            ])
            for action in rec.get('action_items', []):
                report_lines.append(f"  - {action}")
        
        report_lines.append("\n" + "=" * 80)
        report_lines.append("æŠ¥å‘Šç»“æŸ")
        report_lines.append("=" * 80)
        
        report_text = "\n".join(report_lines)
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œä¿å­˜æŠ¥å‘Š
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
        
        return report_text
    
    def export_feedback_data(self, output_file: str):
        """
        å¯¼å‡ºåé¦ˆæ•°æ®ä¸ºJSONæ ¼å¼
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        analysis = self.analyze_all_feedback()
        
        # åŒæ—¶å¯¼å‡ºåŸå§‹åé¦ˆæ•°æ®
        all_feedbacks = self.db_manager.get_all_feedback(limit=10000)
        raw_data = []
        
        for f in all_feedbacks:
            raw_data.append({
                "id": f.id,
                "session_id": f.session_id,
                "user_id": f.user_id,
                "feedback_type": f.feedback_type,
                "rating": f.rating,
                "comment": f.comment,
                "user_message": f.user_message,
                "bot_response": f.bot_response,
                "created_at": f.created_at.isoformat(),
                "is_resolved": f.is_resolved
            })
        
        export_data = {
            "export_date": datetime.now().isoformat(),
            "analysis": analysis,
            "raw_feedbacks": raw_data
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
    
    def __del__(self):
        """æ¸…ç†æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'db_manager'):
            self.db_manager.__exit__(None, None, None)


if __name__ == "__main__":
    """å‘½ä»¤è¡Œå·¥å…·ï¼šç”Ÿæˆåé¦ˆåˆ†ææŠ¥å‘Š"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”¨æˆ·åé¦ˆåˆ†æå·¥å…·")
    parser.add_argument('--days', type=int, default=30, help='åˆ†ææœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼ˆé»˜è®¤30å¤©ï¼‰')
    parser.add_argument('--output', type=str, default='feedback_analysis_report.txt', help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶')
    parser.add_argument('--export-json', type=str, help='å¯¼å‡ºJSONæ•°æ®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸ” å¼€å§‹åˆ†æç”¨æˆ·åé¦ˆ...")
    analyzer = FeedbackAnalyzer()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_detailed_report(output_file=args.output)
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")
    print("\n" + report)
    
    # å¯¼å‡ºJSONæ•°æ®
    if args.export_json:
        analyzer.export_feedback_data(args.export_json)
        print(f"\nâœ… æ•°æ®å·²å¯¼å‡º: {args.export_json}")

