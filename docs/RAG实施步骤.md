# å¿ƒè¯­æœºå™¨äºº - RAGç³»ç»Ÿå®æ–½æ­¥éª¤

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†å¿ƒè¯­ï¼ˆHeartTalkï¼‰æƒ…æ„Ÿé™ªä¼´æœºå™¨äººçš„RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿå®æ–½è¿‡ç¨‹ï¼Œå±•ç¤ºå¦‚ä½•å°†ä¸“ä¸šå¿ƒç†å¥åº·çŸ¥è¯†åº“é›†æˆåˆ°AIå¯¹è¯ç³»ç»Ÿä¸­ã€‚

åŒæ—¶ï¼Œæœ¬æ–‡æ¡£ä¹Ÿè¯´æ˜äº†å‘é‡æ•°æ®åº“åœ¨é¡¹ç›®ä¸­çš„åŒé‡åº”ç”¨ï¼š
1. **RAGçŸ¥è¯†åº“ç³»ç»Ÿ**ï¼šå­˜å‚¨ä¸“ä¸šå¿ƒç†å¥åº·çŸ¥è¯†ï¼Œç”¨äºæ£€ç´¢å¢å¼ºç”Ÿæˆ
2. **ç”¨æˆ·è®°å¿†ç³»ç»Ÿ**ï¼šå­˜å‚¨ç”¨æˆ·å¯¹è¯è®°å¿†ï¼Œå®ç°ä¸ªæ€§åŒ–é™ªä¼´

---

## 3.1 æŠ€æœ¯æ¶æ„

### 3.1.1 RAGçŸ¥è¯†åº“ç³»ç»Ÿæ¶æ„

```
RAGçŸ¥è¯†åº“ç³»ç»Ÿ
â”œâ”€â”€ çŸ¥è¯†åº“æ ¸å¿ƒå±‚ (knowledge_base.py)
â”‚   â”œâ”€â”€ KnowledgeBaseManager - çŸ¥è¯†åº“ç®¡ç†å™¨
â”‚   â””â”€â”€ PsychologyKnowledgeLoader - å¿ƒç†çŸ¥è¯†åŠ è½½å™¨
â”‚
â”œâ”€â”€ RAGæœåŠ¡å±‚ (rag_service.py)
â”‚   â”œâ”€â”€ RAGService - æ£€ç´¢å¢å¼ºç”ŸæˆæœåŠ¡
â”‚   â””â”€â”€ RAGIntegrationService - RAGé›†æˆæœåŠ¡
â”‚
â”œâ”€â”€ è·¯ç”±å±‚ (rag_router.py)
â”‚   â””â”€â”€ æä¾›RESTful APIæ¥å£
â”‚
â””â”€â”€ ChatæœåŠ¡é›†æˆ (chat_service.py)
    â””â”€â”€ è‡ªåŠ¨è¯†åˆ«å¹¶ä½¿ç”¨RAGå¢å¼ºå›å¤
```

### 3.1.2 ç”¨æˆ·è®°å¿†ç³»ç»Ÿæ¶æ„

```
ç”¨æˆ·è®°å¿†ç³»ç»Ÿ
â”œâ”€â”€ å‘é‡æ•°æ®åº“å±‚ (vector_store.py)
â”‚   â”œâ”€â”€ VectorStore - ChromaDBå°è£…
â”‚   â””â”€â”€ user_memories é›†åˆ - ç”¨æˆ·è®°å¿†å‘é‡å­˜å‚¨
â”‚
â”œâ”€â”€ è®°å¿†ç®¡ç†å±‚ (memory_manager.py)
â”‚   â”œâ”€â”€ MemoryManager - è®°å¿†ç®¡ç†å™¨ï¼ˆåŸºç¡€ç‰ˆï¼‰
â”‚   â””â”€â”€ EnhancedMemoryManager - å¢å¼ºç‰ˆè®°å¿†ç®¡ç†å™¨
â”‚
â”œâ”€â”€ ä¸Šä¸‹æ–‡ç»„è£…å±‚ (context_assembler.py)
â”‚   â””â”€â”€ ContextAssembler - æ•´åˆè®°å¿†åˆ°å¯¹è¯ä¸Šä¸‹æ–‡
â”‚
â””â”€â”€ å¯¹è¯æœåŠ¡å±‚ (enhanced_chat_service.py)
    â””â”€â”€ EnhancedChatService - å®Œæ•´å¯¹è¯æµç¨‹ï¼ˆåŒ…å«è®°å¿†æ£€ç´¢å’Œå­˜å‚¨ï¼‰
```

### 3.1.3 å‘é‡æ•°æ®åº“çš„åŒé‡åº”ç”¨

é¡¹ç›®ä¸­çš„ ChromaDB å‘é‡æ•°æ®åº“åŒæ—¶æœåŠ¡äºä¸¤ä¸ªç³»ç»Ÿï¼š

| ç³»ç»Ÿ | é›†åˆåç§° | ç”¨é€” | æ•°æ®æ¥æº |
|------|---------|------|---------|
| **RAGçŸ¥è¯†åº“** | `psychology_kb` | å­˜å‚¨ä¸“ä¸šå¿ƒç†å¥åº·çŸ¥è¯† | PDFæ–‡æ¡£ã€å†…ç½®çŸ¥è¯†åº“ |
| **ç”¨æˆ·è®°å¿†** | `user_memories` | å­˜å‚¨ç”¨æˆ·å¯¹è¯è®°å¿† | ç”¨æˆ·å¯¹è¯å†å² |

**æ ¸å¿ƒåŒºåˆ«ï¼š**
- **RAGçŸ¥è¯†åº“**ï¼šé™æ€çŸ¥è¯†ï¼Œæ‰€æœ‰ç”¨æˆ·å…±äº«ï¼Œç”¨äºæä¾›ä¸“ä¸šå»ºè®®
- **ç”¨æˆ·è®°å¿†**ï¼šåŠ¨æ€è®°å¿†ï¼Œæ¯ä¸ªç”¨æˆ·ç‹¬ç«‹ï¼Œç”¨äºä¸ªæ€§åŒ–é™ªä¼´

---

## 3.2 å®æ–½æ­¥éª¤

### æ­¥éª¤1ï¼šåŠ è½½å¹¶å¤„ç†æ–‡æ¡£

```python
# backend/modules/rag/core/knowledge_base.py

from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document

class KnowledgeBaseManager:
    """å¿ƒç†å¥åº·çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, persist_directory: str = "./chroma_db/psychology_kb"):
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = None
        
        # é…ç½®æ–‡æ¡£åˆ†å—å™¨
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,          # æ¯å—500å­—ç¬¦
            chunk_overlap=50,        # å—é—´é‡å 50å­—ç¬¦
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", ".", "!", "?", ";", " ", ""]
        )
    
    def load_pdf_documents(self, pdf_path: str) -> List[Document]:
        """åŠ è½½PDFæ–‡æ¡£"""
        loader = PyPDFLoader(pdf_path)
        docs = loader.load()
        logger.info(f"æˆåŠŸåŠ è½½PDFæ–‡æ¡£ï¼Œå…± {len(docs)} é¡µ")
        return docs
    
    def split_documents(self, documents: List[Document]) -> List[Document]:
        """åˆ†å‰²æ–‡æ¡£ä¸ºå°å—"""
        chunks = self.text_splitter.split_documents(documents)
        logger.info(f"æ–‡æ¡£åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} ä¸ªæ–‡æ¡£å—")
        return chunks
```

**å®é™…ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
# init_rag_knowledge.py

from backend.modules.rag.core.knowledge_base import KnowledgeBaseManager

# åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨
kb_manager = KnowledgeBaseManager()

# åŠ è½½PDFï¼ˆå¦‚æœæœ‰ï¼‰
# docs = kb_manager.load_pdf_documents("psychology_guide.pdf")

# æˆ–åŠ è½½å†…ç½®ç¤ºä¾‹çŸ¥è¯†
loader = PsychologyKnowledgeLoader(kb_manager)
loader.load_sample_knowledge()  # åŠ è½½å†…ç½®çš„6å¤§ç±»å¿ƒç†å¥åº·çŸ¥è¯†
```

**å†…ç½®çŸ¥è¯†ä¸»é¢˜ï¼š**
1. è®¤çŸ¥è¡Œä¸ºç–—æ³•ï¼ˆCBTï¼‰åŸºç¡€çŸ¥è¯†
2. æ­£å¿µå‡å‹æŠ€æœ¯ï¼ˆMBSRï¼‰
3. ç§¯æå¿ƒç†å­¦å®è·µæŠ€å·§
4. åº”å¯¹ç„¦è™‘çš„å…·ä½“ç­–ç•¥
5. æ”¹å–„ç¡çœ çš„ç§‘å­¦æ–¹æ³•
6. å»ºç«‹å¿ƒç†éŸ§æ€§çš„æ–¹æ³•

---

### æ­¥éª¤2ï¼šç”Ÿæˆå‘é‡å¹¶å­˜å‚¨

```python
# backend/modules/rag/core/knowledge_base.py

from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from datetime import datetime

class KnowledgeBaseManager:
    
    def create_vectorstore(self, chunks: List[Document]) -> Chroma:
        """åˆ›å»ºå‘é‡å­˜å‚¨"""
        logger.info(f"å¼€å§‹åˆ›å»ºå‘é‡å­˜å‚¨ï¼Œå…± {len(chunks)} ä¸ªæ–‡æ¡£å—")
        
        # ä¸ºæ¯ä¸ªæ–‡æ¡£å—æ·»åŠ å…ƒæ•°æ®
        for i, chunk in enumerate(chunks):
            if 'chunk_id' not in chunk.metadata:
                chunk.metadata['chunk_id'] = i
            if 'timestamp' not in chunk.metadata:
                chunk.metadata['timestamp'] = datetime.now().isoformat()
        
        # åˆ›å»ºå‘é‡å­˜å‚¨å¹¶æŒä¹…åŒ–
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.persist_directory
        )
        vectorstore.persist()
        
        self.vectorstore = vectorstore
        logger.info("å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆå¹¶æŒä¹…åŒ–")
        return vectorstore
    
    def load_vectorstore(self) -> Chroma:
        """åŠ è½½å·²å­˜åœ¨çš„å‘é‡å­˜å‚¨"""
        self.vectorstore = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings
        )
        logger.info("å‘é‡å­˜å‚¨åŠ è½½æˆåŠŸ")
        return self.vectorstore
    
    def search_similar(self, query: str, k: int = 3) -> List[Document]:
        """ç›¸ä¼¼åº¦æœç´¢"""
        if self.vectorstore is None:
            self.load_vectorstore()
        
        results = self.vectorstore.similarity_search(query, k=k)
        logger.info(f"æœç´¢å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
        return results
```

**åˆå§‹åŒ–çŸ¥è¯†åº“ï¼š**

```bash
# æ–¹æ³•1: ä½¿ç”¨å‘½ä»¤è¡Œè„šæœ¬
python init_rag_knowledge.py

# æ–¹æ³•2: é€šè¿‡API
curl -X POST http://localhost:8000/api/rag/init/sample
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
======================================================================
 å¿ƒè¯­æœºå™¨äºº - RAGçŸ¥è¯†åº“åˆå§‹åŒ–
======================================================================

â†’ æ­¥éª¤ 1/3: åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨...
âœ“ çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ

â†’ æ­¥éª¤ 2/3: åŠ è½½å¿ƒç†å¥åº·çŸ¥è¯†...
âœ“ å¿ƒç†å¥åº·çŸ¥è¯†åŠ è½½æˆåŠŸ

â†’ æ­¥éª¤ 3/3: éªŒè¯çŸ¥è¯†åº“...
âœ“ çŸ¥è¯†åº“éªŒè¯æˆåŠŸ

----------------------------------------------------------------------
çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯:
  çŠ¶æ€: å°±ç»ª
  æ–‡æ¡£æ•°é‡: 150
  å­˜å‚¨ä½ç½®: ./chroma_db/psychology_kb
  åµŒå…¥æ¨¡å‹: OpenAI Ada-002
----------------------------------------------------------------------
```

---

### æ­¥éª¤3ï¼šå®ç°æ£€ç´¢ä¸ç”Ÿæˆé“¾è·¯

```python
# backend/modules/rag/services/rag_service.py

from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

class RAGService:
    """RAGæ£€ç´¢å¢å¼ºç”ŸæˆæœåŠ¡"""
    
    def __init__(self, kb_manager: Optional[KnowledgeBaseManager] = None):
        if kb_manager is None:
            kb_manager = KnowledgeBaseManager()
            kb_manager.load_vectorstore()
        
        self.kb_manager = kb_manager
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        
        # å¿ƒç†å¥åº·ä¸“ç”¨promptæ¨¡æ¿
        self.prompt_template = PromptTemplate(
            template="""ä½ æ˜¯"å¿ƒè¯­"ï¼Œä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å¥åº·é™ªä¼´æœºå™¨äººã€‚

å‚è€ƒçŸ¥è¯†ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†ï¼Œç”¨æ¸©æš–ã€å…±æƒ…å’Œä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·ã€‚æ³¨æ„ï¼š
1. ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“ä¸­çš„ç§‘å­¦æ–¹æ³•å’ŒæŠ€å·§
2. ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šä¸“ä¸šæ¦‚å¿µ
3. æä¾›å…·ä½“å¯æ“ä½œçš„å»ºè®®
4. è¡¨è¾¾å…±æƒ…å’Œæ”¯æŒ
5. å¦‚æœçŸ¥è¯†åº“ä¸­æœ‰ç›¸å…³ç»ƒä¹ æˆ–æŠ€å·§ï¼Œè¯¦ç»†è¯´æ˜æ­¥éª¤
6. è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥çš„æŒ‡å¯¼æˆ–é™ªä¼´

å›ç­”ï¼š""",
            input_variables=["context", "question"]
        )
    
    def create_qa_chain(self, search_k: int = 3) -> RetrievalQA:
        """åˆ›å»ºQAé“¾"""
        retriever = self.kb_manager.get_retriever(search_kwargs={"k": search_k})
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": self.prompt_template}
        )
        return qa_chain
    
    def ask(self, question: str, search_k: int = 3) -> Dict[str, Any]:
        """å‘çŸ¥è¯†åº“æé—®"""
        # åˆ›å»ºQAé“¾
        qa_chain = self.create_qa_chain(search_k)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = qa_chain({"query": question})
        
        # æå–ç­”æ¡ˆå’Œæ¥æº
        answer = result["result"]
        source_documents = result.get("source_documents", [])
        
        # æ•´ç†æ¥æºä¿¡æ¯
        sources = []
        for doc in source_documents:
            source_info = {
                "content": doc.page_content[:200] + "...",
                "metadata": doc.metadata
            }
            sources.append(source_info)
        
        return {
            "answer": answer,
            "sources": sources,
            "question": question,
            "knowledge_count": len(sources)
        }
    
    def ask_with_context(
        self,
        question: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        user_emotion: Optional[str] = None,
        search_k: int = 3
    ) -> Dict[str, Any]:
        """ç»“åˆå¯¹è¯ä¸Šä¸‹æ–‡å’Œç”¨æˆ·æƒ…ç»ªçš„çŸ¥è¯†é—®ç­”"""
        # æ£€ç´¢ç›¸å…³çŸ¥è¯†
        knowledge_docs = self.kb_manager.search_similar(question, k=search_k)
        
        # æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
        knowledge_context = "\n\n".join([
            f"ã€çŸ¥è¯†{i+1}ã€‘{doc.page_content}"
            for i, doc in enumerate(knowledge_docs)
        ])
        
        # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
        history_context = ""
        if conversation_history:
            recent_history = conversation_history[-3:]
            history_lines = [
                f"{'ç”¨æˆ·' if msg['role']=='user' else 'å¿ƒè¯­'}: {msg['content']}"
                for msg in recent_history
            ]
            history_context = "\n".join(history_lines)
        
        # æ„å»ºæƒ…ç»ªä¸Šä¸‹æ–‡
        emotion_context = f"ç”¨æˆ·å½“å‰æƒ…ç»ª: {user_emotion}" if user_emotion else ""
        
        # æ„å»ºå®Œæ•´prompt
        enhanced_prompt = f"""ä½ æ˜¯"å¿ƒè¯­"ï¼Œä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å¥åº·é™ªä¼´æœºå™¨äººã€‚

{emotion_context}

æœ€è¿‘å¯¹è¯ï¼š
{history_context}

å‚è€ƒçš„ä¸“ä¸šçŸ¥è¯†ï¼š
{knowledge_context}

ç”¨æˆ·å½“å‰é—®é¢˜ï¼š{question}

è¯·åŸºäºä¸Šè¿°ä¸“ä¸šçŸ¥è¯†å’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œç”¨æ¸©æš–ã€å…±æƒ…å’Œä¸“ä¸šçš„è¯­æ°”å›ç­”ç”¨æˆ·ã€‚"""
        
        # ä½¿ç”¨LLMç”Ÿæˆå›ç­”
        response = self.llm.predict(enhanced_prompt)
        
        # æ•´ç†æ¥æºä¿¡æ¯
        sources = [
            {
                "content": doc.page_content[:200] + "...",
                "metadata": doc.metadata
            }
            for doc in knowledge_docs
        ]
        
        return {
            "answer": response,
            "sources": sources,
            "question": question,
            "knowledge_count": len(sources),
            "used_emotion_context": user_emotion is not None,
            "used_history_context": conversation_history is not None
        }


class RAGIntegrationService:
    """RAGé›†æˆæœåŠ¡ - æ™ºèƒ½åˆ¤æ–­ä½•æ—¶ä½¿ç”¨RAG"""
    
    def __init__(self, rag_service: Optional[RAGService] = None):
        self.rag_service = rag_service or RAGService()
    
    def should_use_rag(self, message: str, emotion: Optional[str] = None) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨RAG"""
        # è§¦å‘RAGçš„å…³é”®è¯
        rag_triggers = [
            "æ€ä¹ˆåŠ", "å¦‚ä½•", "æ–¹æ³•", "å»ºè®®", "æŠ€å·§", "ç»ƒä¹ ",
            "å¤±çœ ", "ç„¦è™‘", "æŠ‘éƒ", "å‹åŠ›", "ç´§å¼ ", "æ‹…å¿ƒ",
            "æ­£å¿µ", "å†¥æƒ³", "æ”¾æ¾", "å‘¼å¸", "è®¤çŸ¥", "è¡Œä¸º"
        ]
        
        # éœ€è¦ä¸“ä¸šå»ºè®®çš„æƒ…ç»ª
        professional_emotions = [
            "ç„¦è™‘", "æŠ‘éƒ", "å‹åŠ›å¤§", "ç´§å¼ ", "ææƒ§", "æ‚²ä¼¤"
        ]
        
        # æ£€æŸ¥æ˜¯å¦è§¦å‘
        has_trigger = any(trigger in message.lower() for trigger in rag_triggers)
        needs_professional = emotion and any(prof in emotion for prof in professional_emotions)
        rag_available = self.rag_service.is_knowledge_available()
        
        return (has_trigger or needs_professional) and rag_available
    
    def enhance_response(
        self,
        message: str,
        emotion: Optional[str] = None,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """å¢å¼ºå›å¤"""
        if not self.should_use_rag(message, emotion):
            return {
                "use_rag": False,
                "reason": "å½“å‰å¯¹è¯ä¸éœ€è¦ä¸“ä¸šçŸ¥è¯†åº“æ”¯æŒ"
            }
        
        # ä½¿ç”¨RAGç”Ÿæˆå›ç­”
        result = self.rag_service.ask_with_context(
            question=message,
            conversation_history=conversation_history,
            user_emotion=emotion,
            search_k=3
        )
        
        result["use_rag"] = True
        return result
```

**APIä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
import requests

# æ–¹æ³•1: ç›´æ¥å‘çŸ¥è¯†åº“æé—®
response = requests.post(
    "http://localhost:8000/api/rag/ask",
    json={
        "question": "æˆ‘æœ€è¿‘æ€»æ˜¯å¤±çœ ï¼Œæ€ä¹ˆåŠï¼Ÿ",
        "search_k": 3
    }
)

# æ–¹æ³•2: å¸¦ä¸Šä¸‹æ–‡çš„é—®ç­”
response = requests.post(
    "http://localhost:8000/api/rag/ask/context",
    json={
        "question": "æœ‰ä»€ä¹ˆå…·ä½“çš„æ–¹æ³•å¯ä»¥å¸®åŠ©æˆ‘å…¥ç¡å—ï¼Ÿ",
        "user_emotion": "ç„¦è™‘",
        "conversation_history": [
            {"role": "user", "content": "æˆ‘æœ€è¿‘å‹åŠ›å¾ˆå¤§"},
            {"role": "assistant", "content": "æˆ‘ç†è§£ä½ ç°åœ¨çš„å‹åŠ›..."}
        ],
        "search_k": 3
    }
)

# æ–¹æ³•3: é€šè¿‡Chat APIè‡ªåŠ¨ä½¿ç”¨RAGï¼ˆæ¨èï¼‰
response = requests.post(
    "http://localhost:8000/api/chat",
    json={
        "message": "æˆ‘ç»å¸¸å¤±çœ ï¼Œæœ‰ä»€ä¹ˆç§‘å­¦çš„æ–¹æ³•å—ï¼Ÿ",
        "user_id": "user123",
        "session_id": "session456"
    }
)
# Chat APIä¼šè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨RAG
```

---

### æ­¥éª¤4ï¼šæµ‹è¯•æ•ˆæœ

#### 4.1 è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# å®Œæ•´ç³»ç»Ÿæµ‹è¯•
python test_rag_system.py

# RAGæ•ˆæœå¯¹æ¯”æ¼”ç¤º
python demo_rag_comparison.py
```

#### 4.2 æµ‹è¯•ç»“æœå¯¹æ¯”

**æµ‹è¯•æ¡ˆä¾‹ï¼šå¤±çœ é—®é¢˜**

**ç”¨æˆ·ï¼š** "æˆ‘æœ€è¿‘æ€»æ˜¯å¤±çœ ï¼Œæ€ä¹ˆåŠï¼Ÿ"

**âŒ æ— RAGç‰ˆæœ¬ï¼ˆé€šç”¨å›å¤ï¼‰ï¼š**
```
ä½ å¯ä»¥è¯•è¯•å¬å¬è½»éŸ³ä¹ã€å–æ¯çƒ­ç‰›å¥¶ï¼Œæˆ–è€…ç¡å‰ä¸è¦ç©æ‰‹æœºã€‚
ä¿æŒè§„å¾‹ä½œæ¯ä¹Ÿå¾ˆé‡è¦ã€‚
```

**âœ… RAGå¢å¼ºç‰ˆæœ¬ï¼ˆä¸“ä¸šå»ºè®®ï¼‰ï¼š**
```
æˆ‘ç†è§£å¤±çœ çš„å›°æ‰°ï¼Œè¿™ç¡®å®ä¼šå½±å“ç™½å¤©çš„çŠ¶æ€å’Œæƒ…ç»ªã€‚å¤±çœ å¸¸å¸¸ä¸è¿‡åº¦æ€è€ƒå’Œ
èº«ä½“ç´§å¼ æœ‰å…³ã€‚æˆ‘æƒ³åˆ†äº«ä¸€ä¸ªç»è¿‡ç§‘å­¦éªŒè¯çš„æ–¹æ³•â€”â€”æ­£å¿µèº«ä½“æ‰«æç»ƒä¹ ï¼š

å…·ä½“æ­¥éª¤ï¼š
1. å¹³èººåœ¨åºŠä¸Šï¼Œä¿æŒèˆ’é€‚çš„å§¿åŠ¿
2. é—­ä¸Šçœ¼ç›ï¼Œå¼€å§‹æ·±å‘¼å¸å‡ æ¬¡
3. å°†æ³¨æ„åŠ›ä¾æ¬¡é›†ä¸­åœ¨èº«ä½“å„ä¸ªéƒ¨ä½ï¼š
   â€¢ ä»è„šè¶¾å¼€å§‹ï¼Œæ„Ÿå—è„šè¶¾çš„æ„Ÿè§‰
   â€¢ é€æ­¥å‘ä¸Šï¼šè„šæŒ â†’ å°è…¿ â†’ å¤§è…¿ â†’ è…¹éƒ¨ â†’ èƒ¸éƒ¨ â†’ æ‰‹è‡‚ â†’ å¤´éƒ¨
4. è§‚å¯Ÿæ¯ä¸ªéƒ¨ä½çš„æ„Ÿè§‰ï¼Œä¸åšä»»ä½•è¯„åˆ¤
5. å¦‚æœæ„Ÿåˆ°ç´§å¼ ï¼Œæƒ³è±¡å‘¼å¸æµç»è¯¥éƒ¨ä½ï¼Œå¸¦æ¥æ”¾æ¾
6. å¦‚æœæ€ç»ªé£˜èµ°ï¼Œæ¸©æŸ”åœ°å°†æ³¨æ„åŠ›å¸¦å›èº«ä½“

ä¸´åºŠç ”ç©¶è¡¨æ˜ï¼ŒæŒç»­8å‘¨çš„æ­£å¿µèº«ä½“æ‰«æç»ƒä¹ å¯ä»¥æ˜¾è‘—æ”¹å–„å¤±çœ é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯
å…¥ç¡å›°éš¾å’Œç¡çœ è´¨é‡ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œç¡çœ å«ç”Ÿä¹Ÿå¾ˆé‡è¦ï¼š
â€¢ æ¯å¤©åŒä¸€æ—¶é—´èµ·åºŠå’Œç¡è§‰ï¼ˆåŒ…æ‹¬å‘¨æœ«ï¼‰
â€¢ ç¡å‰1å°æ—¶é¿å…ç”µå­å±å¹•ï¼ˆè“å…‰ä¼šå½±å“è¤ªé»‘ç´ åˆ†æ³Œï¼‰
â€¢ ä¿æŒå§å®¤å‡‰çˆ½ï¼ˆ18-20Â°Cæœ€ä½³ï¼‰ã€é»‘æš—å’Œå®‰é™
â€¢ å¦‚æœ20åˆ†é’Ÿå†…ç¡ä¸ç€ï¼Œèµ·åºŠåšäº›å®‰é™çš„æ´»åŠ¨ï¼Œç›´åˆ°æ„Ÿåˆ°å›°å€¦å†å›åºŠä¸Š

éœ€è¦æˆ‘ç°åœ¨é™ªä½ åšä¸€éèº«ä½“æ‰«æç»ƒä¹ å—ï¼Ÿæˆ–è€…ä½ æƒ³äº†è§£æ›´å¤šå…³äºæ”¹å–„ç¡çœ çš„
æ–¹æ³•ï¼Ÿ

ğŸ’¡ [æ­¤å›å¤åŸºäº 3 ä¸ªä¸“ä¸šçŸ¥è¯†æº]
æ¥æºï¼š
  [1] æ­£å¿µå‡å‹æŠ€æœ¯ï¼ˆMBSRï¼‰- å†…ç½®çŸ¥è¯†åº“
  [2] æ”¹å–„ç¡çœ çš„ç§‘å­¦æ–¹æ³• - å†…ç½®çŸ¥è¯†åº“
  [3] è®¤çŸ¥è¡Œä¸ºç–—æ³•ï¼ˆCBTï¼‰åŸºç¡€çŸ¥è¯† - å†…ç½®çŸ¥è¯†åº“
```

#### 4.3 æ•ˆæœå¯¹æ¯”åˆ†æ

| ç»´åº¦ | æ— RAGç‰ˆæœ¬ | RAGå¢å¼ºç‰ˆæœ¬ |
|------|----------|------------|
| **ä¸“ä¸šæ€§** | â­â­ é€šç”¨å»ºè®® | â­â­â­â­â­ ä¸“ä¸šå¿ƒç†å­¦çŸ¥è¯† |
| **å¯æ“ä½œæ€§** | â­â­ æ¨¡ç³Šå»ºè®® | â­â­â­â­â­ è¯¦ç»†æ­¥éª¤è¯´æ˜ |
| **å¯ä¿¡åº¦** | â­â­ æ— æ¥æºå¼•ç”¨ | â­â­â­â­â­ æ ‡æ³¨çŸ¥è¯†æ¥æº |
| **ç§‘å­¦æ€§** | â­â­ å¸¸è¯†æ€§å»ºè®® | â­â­â­â­â­ ä¸´åºŠç ”ç©¶æ”¯æŒ |
| **ä¸ªæ€§åŒ–** | â­â­ é€šç”¨å›å¤ | â­â­â­â­â­ ç»“åˆæƒ…ç»ªå’Œå†å² |

#### 4.4 å®Œæ•´æµ‹è¯•è¾“å‡º

```
======================================================================
| å¿ƒè¯­æœºå™¨äºº - RAGçŸ¥è¯†åº“ç³»ç»Ÿæµ‹è¯•
| æµ‹è¯•æ—¶é—´: 2025-10-16 14:30:00
======================================================================

======================================================================
| 1. æµ‹è¯•çŸ¥è¯†åº“ç®¡ç†å™¨
======================================================================

â†’ åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨...
âœ“ çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ

â†’ åŠ è½½ç¤ºä¾‹å¿ƒç†å¥åº·çŸ¥è¯†...
âœ“ ç¤ºä¾‹çŸ¥è¯†åŠ è½½æˆåŠŸ

â†’ è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯...
âœ“ ç»Ÿè®¡ä¿¡æ¯:
  â€¢ status: å°±ç»ª
  â€¢ document_count: 150
  â€¢ persist_directory: ./chroma_db/psychology_kb
  â€¢ embedding_model: OpenAI Ada-002

======================================================================
| 2. æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
======================================================================

------------------------------------------------------------
| æŸ¥è¯¢: æˆ‘æœ€è¿‘æ€»æ˜¯å¤±çœ ï¼Œæ€ä¹ˆåŠï¼Ÿ
------------------------------------------------------------

æ‰¾åˆ° 3 ä¸ªç›¸å…³æ–‡æ¡£:

ã€ç»“æœ 1ã€‘ç›¸ä¼¼åº¦: 0.2345
ä¸»é¢˜: æ”¹å–„ç¡çœ çš„ç§‘å­¦æ–¹æ³•
æ¥æº: å†…ç½®çŸ¥è¯†åº“
å†…å®¹é¢„è§ˆ: è‰¯å¥½çš„ç¡çœ å¯¹å¿ƒç†å¥åº·è‡³å…³é‡è¦ã€‚ç¡çœ å«ç”Ÿå»ºè®®...

ã€ç»“æœ 2ã€‘ç›¸ä¼¼åº¦: 0.2567
ä¸»é¢˜: æ­£å¿µå‡å‹æŠ€æœ¯ï¼ˆMBSRï¼‰
æ¥æº: å†…ç½®çŸ¥è¯†åº“
å†…å®¹é¢„è§ˆ: èº«ä½“æ‰«æç»ƒä¹ æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ”¾æ¾æŠ€æœ¯...

ã€ç»“æœ 3ã€‘ç›¸ä¼¼åº¦: 0.2891
ä¸»é¢˜: åº”å¯¹ç„¦è™‘çš„å…·ä½“ç­–ç•¥
æ¥æº: å†…ç½®çŸ¥è¯†åº“
å†…å®¹é¢„è§ˆ: æ·±å‘¼å¸æŠ€æœ¯å¯ä»¥å¿«é€Ÿæ¿€æ´»å‰¯äº¤æ„Ÿç¥ç»ç³»ç»Ÿ...

======================================================================
| æµ‹è¯•æ‘˜è¦
======================================================================

æ€»æµ‹è¯•æ•°: 6
é€šè¿‡: 6 âœ“
å¤±è´¥: 0 âœ—
æˆåŠŸç‡: 100.0%

è¯¦ç»†ç»“æœ:
  âœ“ çŸ¥è¯†åº“ç®¡ç†å™¨: é€šè¿‡
  âœ“ ç›¸ä¼¼åº¦æœç´¢: é€šè¿‡
  âœ“ RAGé—®ç­”: é€šè¿‡
  âœ“ å¸¦ä¸Šä¸‹æ–‡RAGé—®ç­”: é€šè¿‡
  âœ“ RAGé›†æˆæœåŠ¡: é€šè¿‡
  âœ“ å®Œæ•´å·¥ä½œæµç¨‹: é€šè¿‡

======================================================================

ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAGç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚
```

---

## 3.3 RAGå¢å¼ºçš„ä¼˜åŠ¿æ€»ç»“

### âœ“ ä¸“ä¸šæ€§æå‡
- **æ— RAG**: é€šç”¨çš„å®‰æ…°å’Œå»ºè®®ï¼Œå¦‚"è¯•è¯•å¬éŸ³ä¹ã€å–çƒ­ç‰›å¥¶"
- **æœ‰RAG**: åŸºäºè®¤çŸ¥è¡Œä¸ºç–—æ³•ã€æ­£å¿µå‡å‹ç­‰æƒå¨å¿ƒç†å­¦çŸ¥è¯†

### âœ“ å¯æ“ä½œæ€§å¢å¼º
- **æ— RAG**: æ¨¡ç³Šçš„å»ºè®®ï¼Œç¼ºä¹å…·ä½“æ­¥éª¤
- **æœ‰RAG**: è¯¦ç»†çš„åˆ†æ­¥æŒ‡å¯¼ï¼Œç”¨æˆ·å¯ä»¥ç«‹å³å®è·µ

### âœ“ å¯ä¿¡åº¦æå‡
- **æ— RAG**: æ— çŸ¥è¯†æ¥æºï¼Œç”¨æˆ·éš¾ä»¥ä¿¡ä»»
- **æœ‰RAG**: å¼•ç”¨ä¸“ä¸šçŸ¥è¯†æºï¼Œå¢å¼ºå¯ä¿¡åº¦å’Œä¸“ä¸šæ€§

### âœ“ ç§‘å­¦æ€§ä¿éšœ
- **æ— RAG**: åŸºäºå¸¸è¯†çš„å»ºè®®
- **æœ‰RAG**: åŒ…å«ä¸´åºŠç ”ç©¶æ”¯æŒçš„æ–¹æ³•ï¼Œå¦‚"8å‘¨æ­£å¿µç»ƒä¹ æ˜¾è‘—æ”¹å–„å¤±çœ "

### âœ“ ä¸ªæ€§åŒ–å›å¤
- **æ— RAG**: åƒç¯‡ä¸€å¾‹çš„é€šç”¨å›å¤
- **æœ‰RAG**: ç»“åˆç”¨æˆ·æƒ…ç»ªã€å¯¹è¯å†å²ï¼Œç”Ÿæˆå®šåˆ¶åŒ–ä¸“ä¸šå»ºè®®

---

## 3.4 ç³»ç»Ÿé…ç½®ä¸éƒ¨ç½²

### ç¯å¢ƒé…ç½®

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# ä¸»è¦æ–°å¢ä¾èµ–ï¼š
# - pypdf==3.17.4          # PDFæ–‡æ¡£å¤„ç†
# - langchain==0.0.350     # RAGæ¡†æ¶
# - chromadb==0.4.18       # å‘é‡æ•°æ®åº“
# - openai==1.3.7          # OpenAI API
# - python-multipart       # æ–‡ä»¶ä¸Šä¼ 
```

### åˆå§‹åŒ–æµç¨‹

```bash
# 1. åˆå§‹åŒ–çŸ¥è¯†åº“
python init_rag_knowledge.py

# 2. éªŒè¯ç³»ç»Ÿ
python test_rag_system.py

# 3. æŸ¥çœ‹å¯¹æ¯”æ¼”ç¤º
python demo_rag_comparison.py

# 4. å¯åŠ¨æœåŠ¡
python run_backend.py
```

### APIæ¥å£

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/api/rag/status` | GET | è·å–çŸ¥è¯†åº“çŠ¶æ€ |
| `/api/rag/init/sample` | POST | åˆå§‹åŒ–ç¤ºä¾‹çŸ¥è¯† |
| `/api/rag/upload/pdf` | POST | ä¸Šä¼ PDFæ–‡æ¡£ |
| `/api/rag/ask` | POST | çŸ¥è¯†é—®ç­” |
| `/api/rag/ask/context` | POST | å¸¦ä¸Šä¸‹æ–‡é—®ç­” |
| `/api/rag/search` | POST | æœç´¢çŸ¥è¯† |
| `/api/rag/examples` | GET | è·å–ç¤ºä¾‹é—®é¢˜ |

---

## 3.5 æ ¸å¿ƒä»£ç æ–‡ä»¶

| æ–‡ä»¶è·¯å¾„ | åŠŸèƒ½è¯´æ˜ |
|---------|----------|
| `backend/modules/rag/core/knowledge_base.py` | çŸ¥è¯†åº“ç®¡ç†æ ¸å¿ƒï¼Œè´Ÿè´£æ–‡æ¡£åŠ è½½ã€åˆ†å—ã€å‘é‡åŒ–ã€æ£€ç´¢ |
| `backend/modules/rag/services/rag_service.py` | RAGæœåŠ¡å±‚ï¼Œå®ç°æ£€ç´¢å¢å¼ºç”Ÿæˆã€æ™ºèƒ½è§¦å‘åˆ¤æ–­ |
| `backend/modules/rag/routers/rag_router.py` | RAG APIè·¯ç”±ï¼Œæä¾›RESTfulæ¥å£ |
| `init_rag_knowledge.py` | çŸ¥è¯†åº“åˆå§‹åŒ–è„šæœ¬ |
| `test_rag_system.py` | å®Œæ•´ç³»ç»Ÿæµ‹è¯•è„šæœ¬ |
| `demo_rag_comparison.py` | RAGæ•ˆæœå¯¹æ¯”æ¼”ç¤ºè„šæœ¬ |

---

## 3.6 æŠ€æœ¯å‚æ•°è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|---|------|
| **chunk_size** | 500 | æ–‡æ¡£åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰ |
| **chunk_overlap** | 50 | æ–‡æ¡£å—é—´é‡å ï¼ˆå­—ç¬¦æ•°ï¼‰ |
| **embedding_model** | text-embedding-ada-002 | OpenAIåµŒå…¥æ¨¡å‹ |
| **embedding_dimension** | 1536 | å‘é‡ç»´åº¦ |
| **llm_model** | gpt-4 | ç”Ÿæˆæ¨¡å‹ |
| **temperature** | 0.7 | ç”Ÿæˆæ¸©åº¦ï¼ˆå¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§ï¼‰ |
| **search_k** | 3 | é»˜è®¤æ£€ç´¢æ–‡æ¡£æ•°é‡ |
| **persist_directory** | ./chroma_db/psychology_kb | å‘é‡æ•°æ®åº“å­˜å‚¨è·¯å¾„ |

---

## 3.7 åˆ†å—ç­–ç•¥è¯¦è§£

RAGç³»ç»Ÿçš„æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ–‡æ¡£åˆ†å—çš„è´¨é‡ã€‚ä¸å½“çš„åˆ†å—ä¼šç ´åè¯­ä¹‰è¾¹ç•Œï¼Œå¯¼è‡´æ£€ç´¢åˆ°çš„ç‰‡æ®µä¿¡æ¯æ®‹ç¼ºã€ä¸Šä¸‹æ–‡ç¼ºå¤±ã€‚æœ¬ç³»ç»Ÿå®ç°äº†å¤šç§åˆ†å—ç­–ç•¥ï¼Œå¯æ ¹æ®æ–‡æ¡£ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥ã€‚

### 3.7.1 åŸºç¡€åˆ†å—ç­–ç•¥

#### å›ºå®šé•¿åº¦åˆ†å—ï¼ˆCharacterï¼‰

**ç­–ç•¥è¯´æ˜**: æŒ‰é¢„è®¾å­—ç¬¦æ•°ç›´æ¥åˆ‡åˆ†ï¼Œä¸è€ƒè™‘æ–‡æœ¬ç»“æ„ã€‚

**ä¼˜ç‚¹**: å®ç°ç®€å•ã€é€Ÿåº¦å¿«ã€å¯¹ä»»æ„æ–‡æœ¬é€šç”¨ã€‚

**ç¼ºç‚¹**: å®¹æ˜“ç ´åè¯­ä¹‰è¾¹ç•Œï¼›å—è¿‡å¤§å®¹æ˜“å¼•å…¥å™ªå£°ï¼Œè¿‡å°åˆ™ä¸Šä¸‹æ–‡ä¸è¶³ã€‚

**é€‚ç”¨åœºæ™¯**: ç»“æ„æ€§å¼±çš„çº¯æ–‡æœ¬ï¼Œæˆ–æ•°æ®é¢„å¤„ç†åˆæœŸçš„åŸºçº¿æ–¹æ¡ˆã€‚

**å‚æ•°å»ºè®®ï¼ˆä¸­æ–‡è¯­æ–™ï¼‰**:
- `chunk_size`: 300-800 å­—ç¬¦
- `chunk_overlap`: 10%-20%

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import CharacterTextSplitter

splitter = CharacterTextSplitter(
    chunk_size=600,
    chunk_overlap=90
)
chunks = splitter.split_documents(documents)
```

#### åŸºäºå¥å­çš„åˆ†å—ï¼ˆSentenceï¼‰

**ç­–ç•¥è¯´æ˜**: å…ˆæŒ‰å¥å­åˆ‡åˆ†ï¼Œå†å°†è‹¥å¹²å¥å­èšåˆæˆæ»¡è¶³chunk_sizeçš„å—ã€‚

**ä¼˜ç‚¹**: å¥å­çº§å®Œæ•´æ€§æœ€å¥½ï¼Œå¯¹é—®å¥/ç­”å¥æ˜ å°„å‹å¥½ï¼Œä¾¿äºé«˜è´¨é‡å¼•ç”¨ã€‚

**ç¼ºç‚¹**: ä¸­æ–‡åˆ†å¥éœ€ç‰¹åˆ«å¤„ç†ï¼›ä»…å¥å­çº§åˆ‡åˆ†å¯èƒ½å¯¼è‡´å—è¿‡çŸ­ã€‚

**é€‚ç”¨åœºæ™¯**: æ³•å¾‹æ³•è§„ã€æ–°é—»ã€å…¬å‘Šã€FAQç­‰ä»¥å¥å­ä¸ºä¸»çš„æ–‡æœ¬ã€‚

**ä¸­æ–‡åˆ†å¥**: ç³»ç»Ÿä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¯†åˆ«ä¸­æ–‡æ ‡ç‚¹ï¼ˆã€‚ï¼ï¼Ÿï¼›ï¼‰è¿›è¡Œåˆ†å¥ã€‚

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import SentenceTextSplitter

splitter = SentenceTextSplitter(
    chunk_size=600,
    chunk_overlap=80
)
chunks = splitter.split_documents(documents)
```

#### é€’å½’å­—ç¬¦åˆ†å—ï¼ˆRecursiveï¼‰

**ç­–ç•¥è¯´æ˜**: ç»™å®šä¸€ç»„ç”±"ç²—åˆ°ç»†"çš„åˆ†éš”ç¬¦ï¼ˆæ®µè½â†’æ¢è¡Œâ†’ç©ºæ ¼â†’å­—ç¬¦ï¼‰ï¼Œè‡ªä¸Šè€Œä¸‹é€’å½’åˆ‡åˆ†ï¼Œåœ¨ä¸è¶…å‡ºchunk_sizeçš„å‰æä¸‹å°½é‡ä¿ç•™è‡ªç„¶è¯­ä¹‰è¾¹ç•Œã€‚

**ä¼˜ç‚¹**: åœ¨"ä¿æŒè¯­ä¹‰è¾¹ç•Œ"å’Œ"æ§åˆ¶å—å¤§å°"ä¹‹é—´å–å¾—ç¨³å¥å¹³è¡¡ï¼Œå¯¹å¤§å¤šæ•°æ–‡æœ¬å³æ’å³ç”¨ã€‚

**ç¼ºç‚¹**: åˆ†éš”ç¬¦é…ç½®ä¸å½“ä¼šå¯¼è‡´å—ç²’åº¦å¤±è¡¡ï¼›æåº¦æ ¼å¼åŒ–æ–‡æœ¬ï¼ˆè¡¨æ ¼/ä»£ç ï¼‰æ•ˆæœä¸€èˆ¬ã€‚

**é€‚ç”¨åœºæ™¯**: ç»¼åˆæ€§è¯­æ–™ã€è¯´æ˜æ–‡æ¡£ã€æŠ¥å‘Šã€çŸ¥è¯†åº“æ¡ç›®ã€‚

**åˆ†éš”ç¬¦ä¼˜å…ˆçº§**:
1. æ®µè½: `\n\n`
2. æ¢è¡Œ: `\n`
3. ä¸­æ–‡æ ‡ç‚¹: `ã€‚ï¼ï¼Ÿï¼›`
4. è‹±æ–‡æ ‡ç‚¹: `. ! ? ;`
5. ç©ºæ ¼: ` `
6. å­—ç¬¦çº§: `""`ï¼ˆå…œåº•ï¼‰

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.langchain_compat import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=700,
    chunk_overlap=100,
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", ".", "!", "?", ";", " ", ""]
)
chunks = splitter.split_documents(documents)
```

### 3.7.2 ç»“æ„æ„ŸçŸ¥åˆ†å—ç­–ç•¥

#### Markdownç»“æ„åŒ–åˆ†å—ï¼ˆStructureï¼‰

**ç­–ç•¥è¯´æ˜**: åˆ©ç”¨æ–‡æ¡£å›ºæœ‰ç»“æ„ï¼ˆæ ‡é¢˜å±‚çº§ã€åˆ—è¡¨ã€ä»£ç å—ã€è¡¨æ ¼ï¼‰ä½œä¸ºåˆ†å—è¾¹ç•Œï¼Œé€»è¾‘æ¸…æ™°ã€å¯è¿½æº¯æ€§å¼ºã€‚

**ä¼˜ç‚¹**: ä¿è¯ä¸Šä¸‹æ–‡å®Œæ•´æ€§ï¼Œæå‡æ£€ç´¢ä¿¡å™ªæ¯”ï¼Œä¿ç•™æ ‡é¢˜è·¯å¾„ä¾¿äºæº¯æºã€‚

**ç¼ºç‚¹**: ä»…é€‚ç”¨äºç»“æ„åŒ–æ–‡æ¡£ï¼›éœ€è¦æ–‡æ¡£æœ‰æ¸…æ™°çš„æ ‡é¢˜å±‚çº§ã€‚

**é€‚ç”¨åœºæ™¯**: Markdownæ–‡æ¡£ã€æŠ€æœ¯æ‰‹å†Œã€APIæ–‡æ¡£ã€ç»“æ„åŒ–çŸ¥è¯†åº“ã€‚

**å®æ–½æ­¥éª¤**:
1. è§£æMarkdownç»“æ„ï¼ˆè¯†åˆ«æ ‡é¢˜ã€ä»£ç å—ã€è¡¨æ ¼ï¼‰
2. ç”Ÿæˆç« èŠ‚ï¼ˆä»¥æ ‡é¢˜ä¸ºçˆ¶èŠ‚ç‚¹ï¼‰
3. äºŒæ¬¡åˆ‡åˆ†ï¼ˆç« èŠ‚è¶…å‡ºchunk_sizeæ—¶æŒ‰æ®µè½åˆ‡åˆ†ï¼‰
4. åˆå¹¶çŸ­å—ï¼ˆä½äºmin_chunkçš„å—ä¸ç›¸é‚»å—åˆå¹¶ï¼‰
5. æ·»åŠ æ ‡é¢˜è·¯å¾„å‰ç¼€

**å‚æ•°å»ºè®®**:
- `chunk_size`: 600-1000 å­—ç¬¦
- `min_chunk`: 200-300 å­—ç¬¦
- `chunk_overlap`: 10%-15%

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import MarkdownStructureSplitter

splitter = MarkdownStructureSplitter(
    chunk_size=900,
    min_chunk=250,
    overlap_ratio=0.1
)
chunks = splitter.split_documents(documents)
```

**å…ƒæ•°æ®å¢å¼º**: æ¯ä¸ªå—åŒ…å«ï¼š
- `section_title`: ç« èŠ‚æ ‡é¢˜
- `breadcrumbs`: æ ‡é¢˜è·¯å¾„ï¼ˆå¦‚ ["æŒ‡å—", "å®‰è£…", "æ­¥éª¤1"]ï¼‰
- `section_level`: æ ‡é¢˜å±‚çº§ï¼ˆ1-6ï¼‰

#### å¯¹è¯å¼åˆ†å—ï¼ˆDialogueï¼‰

**ç­–ç•¥è¯´æ˜**: ä»¥"è½®æ¬¡/è¯´è¯äºº"ä¸ºè¾¹ç•Œï¼Œä¼˜å…ˆæŒ‰å¯¹è¯é‚»æ¥å¯¹å’Œå°æ®µè¯é¢˜çª—å£èšåˆã€‚

**ä¼˜ç‚¹**: ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡å®Œæ•´ï¼Œä¾¿äºç†è§£é—®ç­”å¯¹å…³ç³»ã€‚

**ç¼ºç‚¹**: ä»…é€‚ç”¨äºå¯¹è¯æ ¼å¼æ–‡æ¡£ã€‚

**é€‚ç”¨åœºæ™¯**: å®¢æœå¯¹è¯ã€è®¿è°ˆã€ä¼šè®®çºªè¦ã€æŠ€æœ¯æ”¯æŒå·¥å•ç­‰å¤šè½®äº¤æµã€‚

**å‚æ•°å»ºè®®**:
- `max_turns`: 6-12 è½®
- `max_chars`: 600-1000 å­—ç¬¦
- `overlap_turns`: 1-2 è½®

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import DialogueSplitter

splitter = DialogueSplitter(
    max_turns=10,
    max_chars=900,
    overlap_turns=2
)
chunks = splitter.split_documents(documents)
```

### 3.7.3 é«˜çº§åˆ†å—ç­–ç•¥

#### å°-å¤§åˆ†å—ï¼ˆSmall-Bigï¼‰

**ç­–ç•¥è¯´æ˜**: ç”¨"å°ç²’åº¦å—"ï¼ˆå¥å­/çŸ­å¥ï¼‰åšé«˜ç²¾åº¦å¬å›ï¼Œå®šä½åˆ°æœ€ç›¸å…³çš„å¾®ç‰‡æ®µï¼›å†å°†å…¶"æ‰€åœ¨çš„å¤§ç²’åº¦å—"ï¼ˆæ®µè½/å°èŠ‚ï¼‰ä½œä¸ºä¸Šä¸‹æ–‡é€å…¥LLMã€‚

**ä¼˜ç‚¹**: å…¼é¡¾ç²¾ç¡®æ€§ä¸ä¸Šä¸‹æ–‡å®Œæ•´æ€§ï¼Œæ£€ç´¢ç²¾åº¦é«˜ä¸”ç­”æ¡ˆè¿è´¯ã€‚

**ç¼ºç‚¹**: ç´¢å¼•ä½“ç§¯å¢å¤§ï¼Œæ£€ç´¢æ—¶éœ€è¦é¢å¤–çš„èšåˆæ­¥éª¤ã€‚

**é€‚ç”¨åœºæ™¯**: éœ€è¦é«˜ç²¾åº¦æ£€ç´¢å’Œå®Œæ•´ä¸Šä¸‹æ–‡çš„åœºæ™¯ã€‚

**å·¥ä½œæµç¨‹**:
1. **ç¦»çº¿æ„å»ºç´¢å¼•**:
   - åˆ›å»ºå°å—ç´¢å¼•ï¼ˆå¥å­çº§ï¼Œç”¨äºå¬å›ï¼‰
   - åˆ›å»ºå¤§å—å­˜å‚¨ï¼ˆæ®µè½çº§ï¼Œç”¨äºä¸Šä¸‹æ–‡ï¼‰
   - å»ºç«‹å°å—åˆ°å¤§å—çš„æ˜ å°„å…³ç³»

2. **åœ¨çº¿æ£€ç´¢**:
   - ç”¨å°å—ç´¢å¼•å¬å›top_kä¸ªå°å—
   - æŒ‰parent_idåˆ†ç»„ï¼Œé€‰å‡ºtop_mä¸ªå¤§å—å€™é€‰
   - åœ¨çˆ¶å—ä¸­é«˜äº®æˆ–ä¿ç•™å‘½ä¸­å°å¥é™„è¿‘çš„ä¸Šä¸‹æ–‡

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import SmallBigChunking

splitter = SmallBigChunking(
    small_chunk_size=200,  # å°å—ç”¨äºå¬å›
    big_chunk_size=900,    # å¤§å—ç”¨äºä¸Šä¸‹æ–‡
    small_overlap=50,
    big_overlap=90
)
chunks = splitter.split_documents(documents)
```

#### çˆ¶å­æ®µåˆ†å—ï¼ˆParent-Childï¼‰

**ç­–ç•¥è¯´æ˜**: å°†æ–‡æ¡£æŒ‰ç»“æ„å•å…ƒï¼ˆçˆ¶å—ï¼‰åˆ‡åˆ†ï¼Œå†åœ¨æ¯ä¸ªçˆ¶å—å†…åˆ‡å‡ºå­å—ï¼ˆå¥å­/çŸ­æ®µï¼‰ã€‚ä¸ºå­å—å»ºå‘é‡ç´¢å¼•ä»¥åšé«˜ç²¾åº¦å¬å›ï¼Œæ£€ç´¢æ—¶å…ˆå¬å›å­å—ï¼Œå†æ‰©å±•åˆ°çˆ¶å—æˆ–çˆ¶å—ä¸­çš„å±€éƒ¨çª—å£ã€‚

**ä¼˜ç‚¹**: å¥çº§è¯æ®å‡†ç¡® + æ®µ/å°èŠ‚çº§ä¸Šä¸‹æ–‡å®Œæ•´ï¼Œå¯è¿½æº¯æ€§å¼ºã€‚

**ç¼ºç‚¹**: ç´¢å¼•ç»“æ„å¤æ‚ï¼Œéœ€è¦ç»´æŠ¤çˆ¶å­æ˜ å°„å…³ç³»ã€‚

**é€‚ç”¨åœºæ™¯**: ç»“æ„æ¸…æ™°çš„è¯´æ˜æ–‡ã€æ‰‹å†Œã€ç™½çš®ä¹¦ã€æ³•è§„ã€FAQèšåˆé¡µã€‚

**å·¥ä½œæµç¨‹**:
1. **ç»“æ„ç²—åˆ‡ï¼ˆçˆ¶å—ï¼‰**: æŒ‰æ ‡é¢˜å±‚çº§/æ®µè½åˆ‡å‡ºçˆ¶å—
2. **ç²¾ç»†åˆ‡åˆ†ï¼ˆå­å—ï¼‰**: åœ¨çˆ¶å—å†…éƒ¨ä»¥å¥å­/å­å¥ä¸ºå•ä½åˆ‡åˆ†
3. **å»ºç´¢å¼•**: å­å—å‘é‡ç´¢å¼•ï¼ˆç”¨äºå¬å›ï¼‰ï¼Œçˆ¶å—å­˜å‚¨ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
4. **æ£€ç´¢ç»„è£…**: å¬å›å­å— â†’ æŒ‰parent_idèšåˆ â†’ åœ¨çˆ¶å—ä¸­æŠ½å–å‘½ä¸­å¥é‚»åŸŸ

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.chunking_strategies import ParentChildChunking

splitter = ParentChildChunking(
    parent_chunk_size=1000,  # çˆ¶å—å¤§å°
    child_chunk_size=300,   # å­å—å¤§å°
    parent_overlap=100,
    child_overlap=50
)
chunks = splitter.split_documents(documents)
```

### 3.7.4 è‡ªåŠ¨ç­–ç•¥é€‰æ‹©

ç³»ç»Ÿå®ç°äº†æ™ºèƒ½ç­–ç•¥é€‰æ‹©å™¨ï¼Œå¯æ ¹æ®æ–‡æ¡£ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³åˆ†å—ç­–ç•¥ã€‚

**æ£€æµ‹é€»è¾‘**:
1. **å¯¹è¯æ£€æµ‹**: è¯†åˆ«å¯¹è¯æ ¼å¼ï¼ˆUser:ã€Assistant:ç­‰ï¼‰ï¼Œä½¿ç”¨`dialogue`ç­–ç•¥
2. **Markdownæ£€æµ‹**: è¯†åˆ«Markdownç»“æ„ï¼ˆæ ‡é¢˜ã€ä»£ç å—ç­‰ï¼‰ï¼Œä½¿ç”¨`structure`ç­–ç•¥
3. **é•¿æ–‡æ¡£æ£€æµ‹**: æ®µè½æ•°>10ä¸”æœ‰ç»“æ„ï¼Œä½¿ç”¨`parent_child`ç­–ç•¥
4. **é•¿å¥å­æ£€æµ‹**: å¹³å‡å¥å­é•¿åº¦>100ï¼Œä½¿ç”¨`sentence`ç­–ç•¥
5. **é»˜è®¤**: ä½¿ç”¨`recursive`ç­–ç•¥

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from backend.modules.rag.core.knowledge_base import KnowledgeBaseManager

# è‡ªåŠ¨é€‰æ‹©ç­–ç•¥
kb_manager = KnowledgeBaseManager(
    chunking_strategy="auto",  # è‡ªåŠ¨é€‰æ‹©
    chunk_size=500,
    chunk_overlap=50
)

# æ‰‹åŠ¨æŒ‡å®šç­–ç•¥
kb_manager = KnowledgeBaseManager(
    chunking_strategy="structure",  # å¼ºåˆ¶ä½¿ç”¨ç»“æ„æ„ŸçŸ¥åˆ†å—
    chunk_size=900,
    chunk_overlap=90
)

# åœ¨åˆ†å—æ—¶æŒ‡å®šç­–ç•¥
chunks = kb_manager.split_documents(documents, strategy="small_big")
```

**ç­–ç•¥å¯¹æ¯”è¡¨**:

| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|---------|------|------|
| **character** | çº¯æ–‡æœ¬ã€åŸºçº¿æ–¹æ¡ˆ | ç®€å•å¿«é€Ÿ | ç ´åè¯­ä¹‰è¾¹ç•Œ |
| **sentence** | å¥å­ä¸ºä¸»æ–‡æœ¬ | å¥å­å®Œæ•´æ€§å¥½ | å—å¯èƒ½è¿‡çŸ­ |
| **recursive** | ç»¼åˆè¯­æ–™ | å¹³è¡¡æ€§å¥½ | æ ¼å¼åŒ–æ–‡æœ¬æ•ˆæœä¸€èˆ¬ |
| **structure** | Markdownæ–‡æ¡£ | ç»“æ„æ¸…æ™°ã€å¯è¿½æº¯ | ä»…é€‚ç”¨ç»“æ„åŒ–æ–‡æ¡£ |
| **dialogue** | å¯¹è¯æ–‡æœ¬ | ä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡ | ä»…é€‚ç”¨å¯¹è¯æ ¼å¼ |
| **small_big** | é«˜ç²¾åº¦æ£€ç´¢ | ç²¾ç¡®+å®Œæ•´ | ç´¢å¼•ä½“ç§¯å¤§ |
| **parent_child** | ç»“æ„åŒ–é•¿æ–‡æ¡£ | å¥çº§å‡†ç¡®+æ®µçº§å®Œæ•´ | ç»“æ„å¤æ‚ |

---

## 3.8 ç­–ç•¥é€‰æ‹©æŒ‡å—

### 3.8.1 å¦‚ä½•é€‰æ‹©åˆ†å—ç­–ç•¥

**å†³ç­–æµç¨‹**:

1. **æ–‡æ¡£ç±»å‹è¯†åˆ«**
   - å¯¹è¯æ ¼å¼ â†’ `dialogue`
   - Markdownæ–‡æ¡£ â†’ `structure`
   - é•¿æ–‡æ¡£ï¼ˆ>10æ®µè½ï¼‰ä¸”æœ‰ç»“æ„ â†’ `parent_child`
   - é•¿å¥å­ï¼ˆå¹³å‡>100å­—ç¬¦ï¼‰ â†’ `sentence`
   - å…¶ä»– â†’ `recursive`

2. **æ€§èƒ½è¦æ±‚**
   - éœ€è¦é«˜ç²¾åº¦å¬å› â†’ `small_big` æˆ– `parent_child`
   - éœ€è¦å¿«é€Ÿå¤„ç† â†’ `character` æˆ– `recursive`
   - éœ€è¦å¯è¿½æº¯æ€§ â†’ `structure` æˆ– `parent_child`

3. **æ–‡æ¡£ç‰¹å¾**
   - æœ‰æ¸…æ™°æ ‡é¢˜å±‚çº§ â†’ `structure`
   - å¥å­ä¸ºä¸» â†’ `sentence`
   - æ— ç‰¹æ®Šç»“æ„ â†’ `recursive`

### 3.8.2 å‚æ•°è°ƒä¼˜å»ºè®®

**chunk_sizeè°ƒä¼˜**:
- ä¸­æ–‡è¯­æ–™: 300-800 å­—ç¬¦èµ·æ­¥
- æŠ€æœ¯æ–‡æ¡£: å¯é€‚å½“å¢å¤§åˆ° 900-1200 å­—ç¬¦
- å¯¹è¯æ–‡æœ¬: 600-1000 å­—ç¬¦

**chunk_overlapè°ƒä¼˜**:
- ä¸€èˆ¬åœºæ™¯: 10%-20%
- éœ€è¦å¼ºä¸Šä¸‹æ–‡è¿ç»­æ€§: 15%-25%
- æ³¨æ„: è¶…è¿‡30%é€šå¸¸å¯¼è‡´ç´¢å¼•ä½“ç§¯æ˜¾è‘—ä¸Šå‡ï¼Œæ”¶ç›Šæœ‰é™

**è°ƒä¼˜æµç¨‹**:
1. å›ºå®šæ£€ç´¢ä¸é‡æ’ï¼ŒåªåŠ¨åˆ†å—å‚æ•°
2. ç”¨éªŒè¯é›†è®¡ç®— Recall@kã€nDCGã€MRR
3. è§‚å¯Ÿå—é•¿åˆ†å¸ƒï¼šé•¿å°¾å¤ªé•¿åˆ™æ”¶ç´§chunk_sizeï¼Œè¿‡çŸ­åˆ™æ”¾å®½
4. è¯„ä¼°ç­”æ¡ˆäº‹å®æ€§ï¼ˆfaithfulnessï¼‰å’Œå¯è¿½æº¯æ€§

### 3.8.3 å®é™…åº”ç”¨ç¤ºä¾‹

**ç¤ºä¾‹1: å¿ƒç†å¥åº·çŸ¥è¯†åº“ï¼ˆMarkdownæ ¼å¼ï¼‰**
```python
kb_manager = KnowledgeBaseManager(
    chunking_strategy="structure",  # ä½¿ç”¨ç»“æ„æ„ŸçŸ¥åˆ†å—
    chunk_size=900,
    chunk_overlap=90
)
```

**ç¤ºä¾‹2: å®¢æœå¯¹è¯è®°å½•**
```python
kb_manager = KnowledgeBaseManager(
    chunking_strategy="dialogue",  # ä½¿ç”¨å¯¹è¯åˆ†å—
    chunk_size=800,
    chunk_overlap=80
)
```

**ç¤ºä¾‹3: æŠ€æœ¯æ–‡æ¡£ï¼ˆéœ€è¦é«˜ç²¾åº¦ï¼‰**
```python
kb_manager = KnowledgeBaseManager(
    chunking_strategy="parent_child",  # ä½¿ç”¨çˆ¶å­æ®µåˆ†å—
    chunk_size=1000,
    chunk_overlap=100
)
```

**ç¤ºä¾‹4: è‡ªåŠ¨é€‰æ‹©ï¼ˆæ¨èï¼‰**
```python
kb_manager = KnowledgeBaseManager(
    chunking_strategy="auto",  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
    chunk_size=500,
    chunk_overlap=50
)
```

---

## 3.9 ç”¨æˆ·è®°å¿†ç³»ç»Ÿé›†æˆ

### 3.9.1 ç³»ç»Ÿæ¦‚è¿°

ç”¨æˆ·è®°å¿†ç³»ç»Ÿæ˜¯"å¿ƒè¯­"æœºå™¨äººçš„æ ¸å¿ƒåŠŸèƒ½ä¹‹ä¸€ï¼Œé€šè¿‡å‘é‡æ•°æ®åº“å®ç°ç”¨æˆ·å¯¹è¯å†å²çš„è¯­ä¹‰è®°å¿†ï¼Œè®©AIèƒ½å¤Ÿ"è®°ä½"ç”¨æˆ·ä¹‹å‰è¯´è¿‡çš„è¯ï¼Œå®ç°çœŸæ­£çš„ä¸ªæ€§åŒ–é™ªä¼´ã€‚

**ä¸RAGç³»ç»Ÿçš„åŒºåˆ«ï¼š**

| ç‰¹æ€§ | RAGçŸ¥è¯†åº“ç³»ç»Ÿ | ç”¨æˆ·è®°å¿†ç³»ç»Ÿ |
|------|--------------|------------|
| **æ•°æ®æ¥æº** | ä¸“ä¸šå¿ƒç†å¥åº·çŸ¥è¯†ï¼ˆé™æ€ï¼‰ | ç”¨æˆ·å¯¹è¯å†å²ï¼ˆåŠ¨æ€ï¼‰ |
| **æ•°æ®å½’å±** | æ‰€æœ‰ç”¨æˆ·å…±äº« | æ¯ä¸ªç”¨æˆ·ç‹¬ç«‹ |
| **æ›´æ–°é¢‘ç‡** | ä½é¢‘ï¼ˆçŸ¥è¯†åº“æ›´æ–°æ—¶ï¼‰ | é«˜é¢‘ï¼ˆæ¯æ¬¡å¯¹è¯ï¼‰ |
| **æ£€ç´¢ç›®çš„** | æä¾›ä¸“ä¸šå»ºè®® | ä¸ªæ€§åŒ–é™ªä¼´ |
| **å­˜å‚¨é›†åˆ** | `psychology_kb` | `user_memories` |

### 3.9.2 æ ¸å¿ƒæ¨¡å—è¯´æ˜

#### 1. å‘é‡æ•°æ®åº“å°è£… (`backend/vector_store.py`)

```python
class VectorStore:
    """å‘é‡æ•°æ®åº“å°è£… - ç»Ÿä¸€ç®¡ç†ChromaDB"""
    
    def __init__(self):
        # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=Config.CHROMA_PERSIST_DIRECTORY,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # åˆ›å»ºå¤šä¸ªé›†åˆ
        self.conversation_collection = ...  # å¯¹è¯è®°å½•
        self.knowledge_collection = ...     # çŸ¥è¯†åº“ï¼ˆRAGï¼‰
        self.emotion_collection = ...       # æƒ…ç»ªç¤ºä¾‹
        self.memory_collection = ...        # ç”¨æˆ·è®°å¿†ï¼ˆç”±MemoryManageråˆ›å»ºï¼‰
```

**å…³é”®ç‚¹ï¼š**
- ä½¿ç”¨åŒä¸€ä¸ªChromaDBå®ä¾‹ï¼Œä½†é€šè¿‡ä¸åŒçš„é›†åˆï¼ˆCollectionï¼‰éš”ç¦»æ•°æ®
- RAGçŸ¥è¯†åº“å’Œç”¨æˆ·è®°å¿†ä½¿ç”¨ä¸åŒçš„é›†åˆï¼Œäº’ä¸å¹²æ‰°

#### 2. è®°å¿†ç®¡ç†å™¨ (`backend/memory_manager.py`)

```python
class MemoryManager:
    """è®°å¿†ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†ç”¨æˆ·çš„é•¿æœŸè®°å¿†"""
    
    def __init__(self):
        self.vector_store = VectorStore()
        self.extractor = MemoryExtractor()
        
        # åˆ›å»ºä¸“é—¨çš„è®°å¿†é›†åˆ
        self.memory_collection = self.vector_store.client.get_or_create_collection(
            name="user_memories",
            embedding_function=default_ef,
            metadata={"hnsw:space": "cosine"}
        )
    
    def store_memory(self, user_id: str, session_id: str, memory: Dict) -> Dict:
        """å­˜å‚¨è®°å¿†åˆ°å‘é‡æ•°æ®åº“"""
        memory_text = f"{memory.get('summary', '')} {memory.get('content', '')}"
        
        metadata = {
            "user_id": user_id,
            "session_id": session_id,
            "type": memory.get("type", "other"),
            "emotion": memory.get("emotion", "neutral"),
            "importance": float(memory.get("importance", 0.5)),
            "timestamp": datetime.now().isoformat()
        }
        
        # å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        self.memory_collection.add(
            documents=[memory_text],
            metadatas=[metadata],
            ids=[memory_id]
        )
    
    def retrieve_memories(self, user_id: str, query: str, n_results: int = 3) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³è®°å¿†"""
        # æŸ¥è¯¢å‘é‡æ•°æ®åº“
        results = self.memory_collection.query(
            query_texts=[query],
            n_results=n_results * 2,
            where={"user_id": user_id}  # åªæ£€ç´¢è¯¥ç”¨æˆ·çš„è®°å¿†
        )
        
        # è¿‡æ»¤å’Œæ’åº
        memories = []
        for i, doc in enumerate(results["documents"][0]):
            # è¿‡æ»¤é‡è¦æ€§ã€æ—¶é—´ç­‰
            # ...
            memories.append({
                "content": doc,
                "metadata": results["metadatas"][0][i],
                "similarity": 1 - (results["distances"][0][i] / 2)
            })
        
        return memories[:n_results]
```

**å…³é”®åŠŸèƒ½ï¼š**
- **æ™ºèƒ½æå–**ï¼šé€šè¿‡`MemoryExtractor`åˆ¤æ–­å“ªäº›å¯¹è¯å€¼å¾—å­˜å‚¨ä¸ºé•¿æœŸè®°å¿†
- **è¯­ä¹‰æ£€ç´¢**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢ç›¸å…³è®°å¿†
- **æ—¶é—´è¡°å‡**ï¼šæ”¯æŒæŒ‰æ—¶é—´èŒƒå›´è¿‡æ»¤è®°å¿†
- **é‡è¦æ€§è¿‡æ»¤**ï¼šåªæ£€ç´¢é‡è¦æ€§è¾¾åˆ°é˜ˆå€¼çš„è®°å¿†

#### 3. ä¸Šä¸‹æ–‡ç»„è£…å™¨ (`backend/context_assembler.py`)

```python
class ContextAssembler:
    """ä¸Šä¸‹æ–‡ç»„è£…å™¨ - æ•´åˆæ‰€æœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    
    def assemble_context(self, user_id: str, session_id: str, 
                        current_message: str, ...) -> Dict:
        """ç»„è£…å®Œæ•´ä¸Šä¸‹æ–‡"""
        # 1. æ£€ç´¢ç›¸å…³è®°å¿†
        memories = self.memory_manager.retrieve_memories(
            user_id=user_id,
            query=current_message,
            n_results=3
        )
        
        # 2. è·å–æƒ…ç»ªè¶‹åŠ¿
        emotion_trend = self.memory_manager.get_user_emotion_trend(user_id, days=7)
        
        # 3. ç»„è£…ä¸Šä¸‹æ–‡
        context = {
            "memories": {
                "recent_events": [...],
                "concerns": [...],
                "all": memories
            },
            "emotion_context": {
                "current_emotion": emotion,
                "trend": emotion_trend
            },
            "chat_history": recent_history
        }
        
        return context
```

**å…³é”®åŠŸèƒ½ï¼š**
- åœ¨ç”Ÿæˆå›å¤å‰æ£€ç´¢ç›¸å…³è®°å¿†
- å°†è®°å¿†æ•´åˆåˆ°Promptä¸­
- æ”¯æŒæƒ…ç»ªè¶‹åŠ¿åˆ†æ

#### 4. å¢å¼ºèŠå¤©æœåŠ¡ (`backend/services/enhanced_chat_service.py`)

```python
class EnhancedChatService:
    """å¢å¼ºç‰ˆèŠå¤©æœåŠ¡ - å®Œæ•´å¯¹è¯æµç¨‹"""
    
    async def chat(self, request: ChatRequest) -> ChatResponse:
        """å¤„ç†èŠå¤©è¯·æ±‚"""
        user_id = request.user_id
        message = request.message
        
        # ============ ç¬¬6æ­¥ï¼šç»„è£…å¢å¼ºä¸Šä¸‹æ–‡ ============
        context = await self.context_assembler.assemble_context(
            user_id=user_id,
            session_id=session_id,
            current_message=message,
            chat_history=chat_history,
            emotion=emotion
        )
        # â†‘ è¿™é‡Œä¼šæ£€ç´¢ç›¸å…³è®°å¿†
        
        # ============ ç¬¬7æ­¥ï¼šæ„å»ºå¢å¼ºPrompt ============
        enhanced_prompt = self.context_assembler.build_prompt_context(
            context, system_prompt
        )
        # â†‘ Promptä¸­åŒ…å«æ£€ç´¢åˆ°çš„è®°å¿†
        
        # ============ ç¬¬9æ­¥ï¼šç”Ÿæˆå›å¤ ============
        response = await self._generate_response(...)
        
        # ============ ç¬¬12æ­¥ï¼šå¤„ç†å¹¶å­˜å‚¨è®°å¿† ============
        await self.memory_manager.process_conversation(
            session_id=session_id,
            user_id=user_id,
            user_message=message,
            bot_response=response.response,
            emotion=emotion
        )
        # â†‘ å¯¹è¯ç»“æŸåï¼Œæå–å¹¶å­˜å‚¨æ–°è®°å¿†
        
        return response
```

### 3.9.3 å®Œæ•´è°ƒç”¨é“¾

```
ç”¨æˆ·å‘é€æ¶ˆæ¯
    â†“
enhanced_chat_service.chat()
    â†“
context_assembler.assemble_context()
    â†“
memory_manager.retrieve_memories()
    â†“
vector_store.memory_collection.query()  â† å‘é‡æ•°æ®åº“æŸ¥è¯¢
    â†“
è¿”å›ç›¸å…³è®°å¿†ï¼ˆå¦‚ï¼š"æˆ‘è®°å¾—ä½ ä¹‹å‰è¯´å·¥ä½œå‹åŠ›å¾ˆå¤§"ï¼‰
    â†“
context_assembler.build_prompt_context()
    â†“
å°†è®°å¿†æ³¨å…¥Promptï¼ˆå¦‚ï¼š"å†å²è®°å¿†ï¼šç”¨æˆ·ä¹‹å‰æåˆ°å·¥ä½œå‹åŠ›å¤§...")
    â†“
LLMç”Ÿæˆå›å¤ï¼ˆåŸºäºè®°å¿†ä¸Šä¸‹æ–‡ï¼‰
    â†“
memory_manager.process_conversation()
    â†“
memory_extractor.extract_memories()  â† åˆ¤æ–­æ˜¯å¦å€¼å¾—å­˜å‚¨
    â†“
memory_manager.store_memory()
    â†“
vector_store.memory_collection.add()  â† å­˜å‚¨æ–°è®°å¿†åˆ°å‘é‡æ•°æ®åº“
```

### 3.9.4 è®°å¿†å­˜å‚¨æµç¨‹

**æ­¥éª¤1ï¼šå¯¹è¯å‘ç”Ÿ**
```python
# ç”¨æˆ·å‘é€æ¶ˆæ¯
user_message = "æœ€è¿‘å·¥ä½œå‹åŠ›å¥½å¤§ï¼Œæ¯å¤©éƒ½åŠ ç­åˆ°å¾ˆæ™šã€‚"
bot_response = "æˆ‘ç†è§£ä½ ç°åœ¨çš„å‹åŠ›çŠ¶å†µ..."
```

**æ­¥éª¤2ï¼šè®°å¿†æå–**
```python
# MemoryExtractoråˆ¤æ–­æ˜¯å¦å€¼å¾—å­˜å‚¨
if should_extract_memory(user_message, emotion, intensity):
    memories = extract_memories(
        user_message, bot_response, emotion, intensity
    )
    # è¿”å›ï¼š
    # {
    #     "type": "concern",
    #     "content": "å·¥ä½œå‹åŠ›å¤§ï¼Œç»å¸¸åŠ ç­",
    #     "emotion": "å‹åŠ›å¤§",
    #     "importance": 0.8
    # }
```

**æ­¥éª¤3ï¼šå‘é‡åŒ–å­˜å‚¨**
```python
# å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
memory_text = "å·¥ä½œå‹åŠ›å¤§ï¼Œç»å¸¸åŠ ç­"
metadata = {
    "user_id": "user123",
    "type": "concern",
    "emotion": "å‹åŠ›å¤§",
    "importance": 0.8,
    "timestamp": "2025-01-16T15:30:00"
}

memory_collection.add(
    documents=[memory_text],
    metadatas=[metadata],
    ids=["user123_abc123"]
)
```

### 3.9.5 è®°å¿†æ£€ç´¢æµç¨‹

**æ­¥éª¤1ï¼šç”¨æˆ·å‘é€æ–°æ¶ˆæ¯**
```python
user_message = "é¡¹ç›®å¿«ä¸Šçº¿äº†ï¼Œè¿™å‘¨åˆè¦å¤©å¤©ç†¬å¤œäº†ã€‚"
```

**æ­¥éª¤2ï¼šå‘é‡ç›¸ä¼¼åº¦æ£€ç´¢**
```python
# å°†ç”¨æˆ·æ¶ˆæ¯å‘é‡åŒ–
query_vector = embedding_model.encode(user_message)

# åœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢
results = memory_collection.query(
    query_embeddings=[query_vector],
    n_results=5,
    where={"user_id": "user123"}  # åªæ£€ç´¢è¯¥ç”¨æˆ·çš„è®°å¿†
)

# è¿”å›ç›¸ä¼¼è®°å¿†ï¼š
# [
#     {
#         "content": "å·¥ä½œå‹åŠ›å¤§ï¼Œç»å¸¸åŠ ç­",
#         "similarity": 0.85,
#         "metadata": {
#             "emotion": "å‹åŠ›å¤§",
#             "timestamp": "2025-01-10T..."
#         }
#     },
#     ...
# ]
```

**æ­¥éª¤3ï¼šè¿‡æ»¤å’Œæ’åº**
```python
# æŒ‰é‡è¦æ€§ã€æ—¶é—´ã€ç›¸ä¼¼åº¦ç»¼åˆæ’åº
filtered_memories = filter_and_sort(
    results,
    min_importance=0.5,
    days_limit=7
)
```

**æ­¥éª¤4ï¼šæ³¨å…¥Prompt**
```python
# æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡
memory_context = """
å†å²è®°å¿†ï¼š
1. [2025-01-10] [å‹åŠ›å¤§] å·¥ä½œå‹åŠ›å¤§ï¼Œç»å¸¸åŠ ç­
2. [2025-01-12] [å‹åŠ›å¤§] æ„Ÿè§‰å¿«æ’‘ä¸ä½äº†
"""

prompt = f"""
ä½ æ˜¯"å¿ƒè¯­"ï¼Œä¸€ä¸ªæ¸©æš–çš„å¿ƒç†é™ªä¼´è€…ã€‚

{memory_context}

å½“å‰è¾“å…¥ï¼š{user_message}

è¯·ç»“åˆå†å²è®°å¿†ï¼Œç”¨å…±æƒ…ã€æ”¯æŒçš„è¯­æ°”å›åº”ã€‚
"""
```

### 3.9.6 è®°å¿†ç³»ç»Ÿä¸RAGç³»ç»Ÿçš„ååŒ

åœ¨å®é™…å¯¹è¯ä¸­ï¼Œä¸¤ä¸ªç³»ç»Ÿå¯ä»¥ååŒå·¥ä½œï¼š

```python
# å®Œæ•´å¯¹è¯æµç¨‹
async def chat_with_rag_and_memory(user_message: str, user_id: str):
    # 1. æ£€ç´¢ç”¨æˆ·è®°å¿†ï¼ˆä¸ªæ€§åŒ–ï¼‰
    memories = memory_manager.retrieve_memories(
        user_id=user_id,
        query=user_message
    )
    
    # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦RAGï¼ˆä¸“ä¸šæ€§ï¼‰
    if rag_service.should_use_rag(user_message, emotion):
        # æ£€ç´¢ä¸“ä¸šçŸ¥è¯†
        knowledge = rag_service.ask_with_context(
            question=user_message,
            conversation_history=chat_history
        )
    else:
        knowledge = None
    
    # 3. ç»„è£…å®Œæ•´ä¸Šä¸‹æ–‡
    context = {
        "user_memories": memories,      # ä¸ªæ€§åŒ–è®°å¿†
        "professional_knowledge": knowledge,  # ä¸“ä¸šçŸ¥è¯†
        "chat_history": chat_history
    }
    
    # 4. ç”Ÿæˆå›å¤
    response = llm.generate(context)
    
    # 5. å­˜å‚¨æ–°è®°å¿†
    memory_manager.process_conversation(...)
    
    return response
```

**ååŒæ•ˆæœç¤ºä¾‹ï¼š**

**ç”¨æˆ·ï¼š** "æˆ‘æœ€è¿‘æ€»æ˜¯å¤±çœ ï¼Œæ€ä¹ˆåŠï¼Ÿ"

**ç³»ç»Ÿå¤„ç†ï¼š**
1. **è®°å¿†æ£€ç´¢**ï¼šå‘ç°ç”¨æˆ·ä¹‹å‰æåˆ°"å·¥ä½œå‹åŠ›å¤§" â†’ å…³è”åˆ°å¤±çœ åŸå› 
2. **RAGæ£€ç´¢**ï¼šæ£€ç´¢"æ”¹å–„ç¡çœ çš„ç§‘å­¦æ–¹æ³•" â†’ æä¾›ä¸“ä¸šå»ºè®®
3. **ç”Ÿæˆå›å¤**ï¼š
   ```
   æˆ‘è®°å¾—ä½ ä¹‹å‰æåˆ°å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œç»å¸¸åŠ ç­ã€‚
   å¤±çœ å¸¸å¸¸ä¸å‹åŠ›å’Œè¿‡åº¦æ€è€ƒæœ‰å…³ã€‚
   
   æˆ‘æƒ³åˆ†äº«ä¸€ä¸ªç»è¿‡ç§‘å­¦éªŒè¯çš„æ–¹æ³•â€”â€”æ­£å¿µèº«ä½“æ‰«æç»ƒä¹ ï¼š
   [è¯¦ç»†æ­¥éª¤...]
   ```

### 3.9.7 å…³é”®æ–‡ä»¶ä½ç½®

| æ–‡ä»¶è·¯å¾„ | åŠŸèƒ½è¯´æ˜ |
|---------|---------|
| `backend/vector_store.py` | å‘é‡æ•°æ®åº“å°è£…ï¼Œç®¡ç†æ‰€æœ‰ChromaDBé›†åˆ |
| `backend/memory_manager.py` | è®°å¿†ç®¡ç†å™¨ï¼Œè´Ÿè´£è®°å¿†çš„å­˜å‚¨å’Œæ£€ç´¢ |
| `backend/context_assembler.py` | ä¸Šä¸‹æ–‡ç»„è£…å™¨ï¼Œæ•´åˆè®°å¿†åˆ°å¯¹è¯ä¸Šä¸‹æ–‡ |
| `backend/services/enhanced_chat_service.py` | å¢å¼ºèŠå¤©æœåŠ¡ï¼Œå®Œæ•´å¯¹è¯æµç¨‹ |
| `backend/services/enhanced_memory_manager.py` | å¢å¼ºç‰ˆè®°å¿†ç®¡ç†å™¨ï¼ˆæ”¯æŒçŸ­æœŸ+é•¿æœŸè®°å¿†ï¼‰ |
| `backend/memory_extractor.py` | è®°å¿†æå–å™¨ï¼Œåˆ¤æ–­å“ªäº›å¯¹è¯å€¼å¾—å­˜å‚¨ |

### 3.9.8 éªŒè¯è®°å¿†ç³»ç»Ÿ

**æ–¹æ³•1ï¼šæŸ¥çœ‹å‘é‡æ•°æ®åº“**
```python
from backend.vector_store import VectorStore

vector_store = VectorStore()
# æŸ¥çœ‹è®°å¿†é›†åˆ
results = vector_store.memory_collection.get(limit=10)
print(f"å…±æœ‰ {len(results['ids'])} æ¡è®°å¿†")
```

**æ–¹æ³•2ï¼šæµ‹è¯•è®°å¿†æ£€ç´¢**
```python
from backend.memory_manager import MemoryManager

memory_manager = MemoryManager()

# æ£€ç´¢è®°å¿†
memories = memory_manager.retrieve_memories(
    user_id="test_user",
    query="å·¥ä½œå‹åŠ›å¤§ï¼Œåˆè¦ç†¬å¤œäº†",
    n_results=3
)

for mem in memories:
    print(f"- {mem['content']} (ç›¸ä¼¼åº¦: {mem['similarity']:.2f})")
```

**æ–¹æ³•3ï¼šæŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾**
```python
# åœ¨ enhanced_chat_service.py ä¸­æ·»åŠ æ—¥å¿—
logger.info(f"æ£€ç´¢åˆ° {len(memories)} æ¡ç›¸å…³è®°å¿†")
logger.info(f"å­˜å‚¨äº† {len(stored_memories)} æ¡æ–°è®°å¿†")
```

---

## 3.10 ç»“è®º

é€šè¿‡RAGæŠ€æœ¯å’Œç”¨æˆ·è®°å¿†ç³»ç»Ÿï¼Œ"å¿ƒè¯­"æƒ…æ„Ÿé™ªä¼´æœºå™¨äººå®ç°äº†ä»**"æƒ…æ„Ÿå€¾å¬è€…"åˆ°"ä¸“ä¸šå¿ƒç†åŠ©æ‰‹"**çš„å‡çº§ï¼š

1. **çŸ¥è¯†é©±åŠ¨**: åŸºäºæƒå¨å¿ƒç†å­¦çŸ¥è¯†åº“ï¼Œè€Œéä»…ä¾èµ–LLMçš„è®­ç»ƒæ•°æ®
2. **ä¸“ä¸šå¯ä¿¡**: å¼•ç”¨çŸ¥è¯†æ¥æºï¼Œæä¾›ç§‘å­¦ä¾æ®ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»
3. **å®ç”¨å¯æ“ä½œ**: æä¾›è¯¦ç»†çš„æ­¥éª¤æŒ‡å¯¼ï¼Œç”¨æˆ·å¯ä»¥ç«‹å³å®è·µ
4. **æ™ºèƒ½è§¦å‘**: è‡ªåŠ¨è¯†åˆ«éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„åœºæ™¯ï¼Œæ— ç¼é›†æˆåˆ°å¯¹è¯æµç¨‹
5. **æŒç»­æ‰©å±•**: æ”¯æŒä¸Šä¼ PDFæ–‡æ¡£ï¼Œä¸æ–­ä¸°å¯ŒçŸ¥è¯†åº“å†…å®¹
6. **ä¸ªæ€§åŒ–è®°å¿†**: é€šè¿‡å‘é‡æ•°æ®åº“å®ç°ç”¨æˆ·å¯¹è¯å†å²çš„è¯­ä¹‰è®°å¿†ï¼Œè®©AI"è®°ä½"ç”¨æˆ·
7. **ååŒå·¥ä½œ**: RAGçŸ¥è¯†åº“å’Œç”¨æˆ·è®°å¿†ç³»ç»ŸååŒï¼Œæ—¢æä¾›ä¸“ä¸šå»ºè®®ï¼Œåˆå®ç°ä¸ªæ€§åŒ–é™ªä¼´

**åŒé‡å‘é‡æ•°æ®åº“åº”ç”¨ï¼š**
- **RAGçŸ¥è¯†åº“ç³»ç»Ÿ**ï¼šå­˜å‚¨ä¸“ä¸šå¿ƒç†å¥åº·çŸ¥è¯†ï¼Œæä¾›ç§‘å­¦ã€ä¸“ä¸šçš„å»ºè®®
- **ç”¨æˆ·è®°å¿†ç³»ç»Ÿ**ï¼šå­˜å‚¨ç”¨æˆ·å¯¹è¯è®°å¿†ï¼Œå®ç°ä¸ªæ€§åŒ–ã€æœ‰è®°å¿†çš„é™ªä¼´

ä¸¤ä¸ªç³»ç»Ÿé€šè¿‡åŒä¸€ä¸ªChromaDBå®ä¾‹çš„ä¸åŒé›†åˆå®ç°ï¼Œæ—¢ä¿è¯äº†æ•°æ®éš”ç¦»ï¼Œåˆå®ç°äº†èµ„æºå…±äº«ã€‚RAGç³»ç»Ÿè®©AIä¸ä»…èƒ½å…±æƒ…ç”¨æˆ·æƒ…ç»ªï¼Œæ›´èƒ½æä¾›ç§‘å­¦ã€ä¸“ä¸šã€å¯æ“ä½œçš„å¿ƒç†å¥åº·å»ºè®®ï¼›è®°å¿†ç³»ç»Ÿè®©AIèƒ½å¤Ÿ"è®°ä½"ç”¨æˆ·ï¼Œå®ç°çœŸæ­£çš„ä¸ªæ€§åŒ–é™ªä¼´ã€‚ä¸¤è€…ç»“åˆï¼ŒçœŸæ­£æˆä¸ºç”¨æˆ·çš„ä¸“ä¸šå¿ƒç†é™ªä¼´åŠ©æ‰‹ã€‚

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-16  
**æ›´æ–°æ—¥æœŸ**: 2025-01-XX  
**é¡¹ç›®**: å¿ƒè¯­ï¼ˆHeartTalkï¼‰æƒ…æ„Ÿé™ªä¼´æœºå™¨äºº  
**å¼€å‘å›¢é˜Ÿ**: å¿ƒè¯­æœºå™¨äººé¡¹ç›®ç»„

---

## æ›´æ–°æ—¥å¿—

### v2.1 (2025-01-XX)
- âœ¨ æ–°å¢ç”¨æˆ·è®°å¿†ç³»ç»Ÿé›†æˆè¯´æ˜
- âœ¨ è¯´æ˜å‘é‡æ•°æ®åº“çš„åŒé‡åº”ç”¨ï¼ˆRAGçŸ¥è¯†åº“ + ç”¨æˆ·è®°å¿†ï¼‰
- âœ¨ æ·»åŠ è®°å¿†ç³»ç»Ÿè°ƒç”¨é“¾å’Œé›†æˆæµç¨‹
- ğŸ“ æ›´æ–°æ–‡æ¡£ï¼Œè¡¥å……è®°å¿†ç³»ç»Ÿä¸RAGç³»ç»Ÿçš„ååŒå·¥ä½œè¯´æ˜

### v2.0 (2025-01-XX)
- âœ¨ æ–°å¢å¤šç§åˆ†å—ç­–ç•¥æ”¯æŒï¼ˆåŸºç¡€åˆ†å—ã€ç»“æ„æ„ŸçŸ¥ã€é«˜çº§åˆ†å—ï¼‰
- âœ¨ å®ç°è‡ªåŠ¨ç­–ç•¥é€‰æ‹©æœºåˆ¶
- âœ¨ æ·»åŠ Markdownç»“æ„åŒ–åˆ†å—
- âœ¨ æ·»åŠ å¯¹è¯å¼åˆ†å—
- âœ¨ æ·»åŠ å°-å¤§åˆ†å—å’Œçˆ¶å­æ®µåˆ†å—ç­–ç•¥
- ğŸ“ æ›´æ–°æ–‡æ¡£ï¼Œè¡¥å……åˆ†å—ç­–ç•¥è¯¦è§£å’Œé€‰æ‹©æŒ‡å—

### v1.0 (2025-10-16)
- åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºç¡€RAGåŠŸèƒ½å®ç°

