# 意图引擎架构设计文档

## 一、问题背景

在电商亿级用户、千万级SKU的复杂生态中，用户意图往往隐含、模糊、多变。传统基于关键词匹配或浅层行为统计的意图识别方法，难以应对以下挑战：

- **长尾Query理解困难**：如"适合小个子夏天通勤的平价连衣裙"，涉及多维度语义理解
- **跨模态意图不一致**：搜索词 vs. 点击行为 vs. 客服对话之间存在语义鸿沟
- **动态购物状态缺失**：无法准确判断用户处于"比价"还是"决策"阶段
- **意图体系僵化**：无法自动发现新需求模式（如"露营经济"相关意图）

因此，亟需构建一个以大模型为核心、多模态融合、可在线服务的意图引擎，为搜索、推荐、广告、客服等下游系统提供统一、精准的用户意图表示。

### 1.1 核心技术目标

| 维度 | 目标 | 技术手段 |
|------|------|---------|
| **精准识别** | 意图准确率≥95%，F1值≥92% | 多模态融合 + 长用户行为 + LLM推理 |
| **低延迟响应** | 搜索/推荐≤300ms，客服≤800ms | 三级漏斗分流 + 模型量化 + 缓存 |
| **成本可控** | 算力成本降低60%+，LLM调用≤0.005元/次 | 分层资源 + 弹性调度 + 开源LLM |
| **业务适配** | 支撑20+类核心意图，亿级用户规模 | 场景定制 + 动态意图发现 |

### 1.2 核心技术逻辑

以 **"多模态上下文补全信息维度、长用户行为锚定个性化偏好、LLM实现语义深度推理"** 为核心，解决传统意图识别的痛点：

| 痛点 | 解决方案 |
|------|---------|
| 信息片面 | 多模态上下文（文本+图像+音频+行为） |
| 个性化不足 | 长用户行为（近3年交易+近1年浏览+偏好特征） |
| 语义模糊 | LLM深度推理（Qwen微调+电商Prompt） |

### 1.3 适用场景

| 场景 | 输入数据 | 识别意图 |
|------|---------|---------|
| **搜索** | 搜索词+历史购买偏好+商品图像 | 比价型搜索、品牌忠诚型搜索 |
| **智能客服** | 咨询文本+语音情感+订单历史 | 物流查询、退款申诉、质量投诉 |
| **拍立淘** | 商品图像+拍摄场景+历史浏览 | 同款低价搜、相似风格推荐 |
| **个性化营销** | 浏览轨迹+优惠券交互+历史成交 | 刚需购买、囤货捡漏、犹豫比价 |

### 1.4 业界实践参考

| 公司 | 系统/项目 | 核心技术 | 业务效果 |
|------|----------|---------|---------|
| **Meta** | Advantage+ 广告引擎 | LLM驱动的重排序层 + Gen AI创意生成 | ROAS提升26%，年化收入200亿美元 |
| **Meta** | DLRM推荐模型 | 双塔Embedding + 稀疏特征交叉 | 广告CTR提升15%+ |
| **阿里** | 通义千问意图识别 | Qwen1.5微调 + 多轮对话理解 | 意图准确率92%+ |
| **字节** | Monolith实时推荐 | 在线学习 + 实时特征更新 | 推荐时效性提升10x |
| **Google** | BERT-based Intent | 预训练+微调 + 多任务学习 | 搜索相关性提升8% |

**Meta Advantage+ 核心架构启示**：
- **LLM重排序层**：在传统推荐模型之上叠加LLM进行语义重排序
- **端到端自动化**：从创意生成到投放优化全链路AI驱动
- **实时反馈闭环**：用户行为实时回流优化模型

---

## 二、意图识别技术综述

> 参考论文：[Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/pdf/2507.22934)

意图识别（Intent Recognition）旨在从用户的自然交互数据（文本、语音、视觉、脑电等）中推断其潜在目标。随着人工智能和深度学习的快速发展，意图识别在人机交互、对话系统、智能家居、医疗健康、智能驾驶等领域发挥着越来越重要的作用。

最早的研究主要集中在单模态（unimodal）意图识别，如基于文本的意图分类。但单一模态容易受噪声、语义歧义或信息缺失影响，难以满足复杂场景需求。因此，近年来研究逐渐转向多模态意图识别（Multimodal Intent Recognition, MIR），通过融合文本、音频、视觉、生理信号等信息来提升准确率与鲁棒性。

### 2.1 单模态意图识别方法

#### 2.1.1 文本意图识别

**发展历程**：

1. **基于规则/机器学习**：如 SVM、决策树，但需要大量特征工程。

![图 3：机器学习的文本意图识别](images/fig3_ml_text_intent.png)

2. **深度学习模型**：CNN 提取局部特征，RNN 建模时序依赖。

![图 4：基于CNN/RNN的文本意图识别](images/fig4_cnn_rnn_text_intent.png)

3. **Transformer & BERT**：引入自注意力机制，大幅提升性能。

![图 5：文本意图识别的BERT模型](images/fig5_bert_text_intent.png)

4. **LLM 阶段**：通过 Prompt + In-Context Learning 支持零样本/小样本意图识别。

![图 6：基于LLM的文本意图识别模型](images/fig6_llm_text_intent.png)

#### 2.1.2 视觉意图识别

从说服性意图识别（视觉线索，如表情、动作、背景）发展到心理学驱动的 Intentonomy 数据集。

**新方法强调**：
- 原型学习（PIP-Net）
- 层次结构（LabCR）
- 多粒度特征（MCCL）

![图 7：视觉意图识别的分类范式和基于原型的范式](images/fig7_visual_intent.png)

#### 2.1.3 音频意图识别

- **传统管线**：ASR + NLU，缺点是误差累积
- **端到端 E2E**：直接从语音到意图分类
- **预训练模型**：Wav2Vec、HuBERT，提升鲁棒性
- **创新方向**：零样本意图识别、语义蒸馏、跨模态对齐

![图 8：三种音频意图识别框架](images/fig8_audio_intent.png)

#### 2.1.4 EEG 意图识别

EEG 主要应用在脑机接口（BCI）场景，如康复、辅助机器人。

- **模型发展**：从 RNN/CNN 到图神经网络（G-CRAM）、Transformer（PerBCI、TSE-DA-AWS）
- **趋势**：跨主体泛化、低成本设备、与其他模态结合

### 2.2 多模态意图识别方法

**三阶段管道**：

1. **特征提取** → 文本用 BERT，语音用 Wav2Vec，视觉用 ResNet/Swin Transformer
2. **多模态表示学习** → 核心环节（融合、对齐、知识增强、多任务）
3. **意图分类** → Softmax / 原型对比学习 / LLM 生成

![图 9：多模态意图识别的深度学习管道](images/fig9_multimodal_pipeline.png)

![图 10：MIR的基本模态融合方法](images/fig10_fusion_methods.png)

**方法分类**：

| 类别 | 方法 | 说明 |
|------|------|------|
| **融合方法** | 特征级（早融合） | 细粒度，但要求模态对齐严格 |
| | 决策级（晚融合） | 独立预测再合并，鲁棒性强 |
| | 混合融合 | 兼顾两者优点 |
| **对齐与解耦** | 对齐 | contrastive learning, cross-modal attention |
| | 解耦 | DuoDN、LVAMoE，分离共享/独有特征 |
| **知识增强** | LLM推理 | 借助 LLM 提供推理能力（如 A-MESS、CaVIR） |
| | 检索增强 | 使用检索增强外部知识 |
| **多任务协同** | 联合优化 | 同时优化意图与情感识别任务，提升鲁棒性 |
| **语义关系推理** | LGSRR | LLM引导的细粒度语义提取 + 逻辑关系建模 |

![图 11：在MIR中的单任务学习和多任务学习](images/fig11_multitask_learning.png)

### 2.3 LLM引导的语义关系推理（LGSRR）

> 参考论文：[LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition](https://arxiv.org/pdf/2509.01337)

现有多模态意图识别方法存在两大局限：
1. **依赖粗粒度语义**：模态级别的融合引入大量冗余和噪声
2. **关系建模能力有限**：简单融合机制（拼接、加权平均）无法建模复杂逻辑关系

#### 2.3.1 LGSRR框架核心思想

**"大模型引导小模型"范式**：利用LLM的强大语义理解能力生成高质量中间监督信号，避免直接部署昂贵的大模型。

```mermaid
graph LR
    A[多模态输入] --> B[LLM引导语义提取]
    B --> C[细粒度语义描述]
    C --> D[语义关系推理模块]
    D --> E[意图分类]
    
    subgraph LLM引导
        B1[Step1: 发现<br/>GPT-3.5归纳语义维度]
        B2[Step2: 描述<br/>VideoLLaMA2生成描述]
        B3[Step3: 排序<br/>GPT-3.5重要性排序]
    end
```

#### 2.3.2 LLM引导的细粒度语义提取

采用 **浅到深的思维链（Shallow-to-Deep CoT）** 策略：

| 步骤 | 模型 | 任务 | 输出 |
|------|------|------|------|
| **Step 1: 发现** | GPT-3.5 | 分析少量样本，归纳关键语义维度 | 说话者动作、面部表情、与他人互动等 |
| **Step 2: 描述** | VideoLLaMA2 | 结合视频和文本，生成详细描述 | 每个语义维度的文本描述 |
| **Step 3: 排序** | GPT-3.5 | 基于真实标签对语义重要性排序 | 监督信号供推理模块学习 |

> ✅ **优势**：无需人工定义先验，完全由LLM自主挖掘高相关性语义

#### 2.3.3 基于逻辑的语义关系推理

受经典逻辑运算启发，建模三种语义关系：

| 逻辑运算 | 语义关系 | 实现方式 | 作用 |
|---------|---------|---------|------|
| **OR** | 相对重要性 | NeuralNDCG排序损失 | 学习LLM提供的重要性排序 |
| **AND** | 互补性 | 余弦相似度加权增强 | 文本与非语言语义互补增强表示 |
| **NOT** | 不一致性 | 均方误差正则化 | 惩罚文本与表情/动作的冲突（如"认真介绍"但表情在开玩笑） |

#### 2.3.4 训练目标设计

将互补性增强的特征与不一致性惩罚特征结合，通过 **交叉熵损失 + NeuralNDCG排序损失** 的加权和作为整体损失函数：

```
L_total = L_ce(分类损失) + λ * L_ndcg(排序损失) + μ * L_mse(不一致性正则化)
```

#### 2.3.5 实验效果

| 数据集 | 任务 | 指标提升 | 相比MLLMs |
|--------|------|---------|----------|
| MIntRec2.0 | 30类细粒度意图识别 | 精确率+1.31%，F1+0.61% | ACC差距超30% |
| IEMOCAP-DA | 12类对话行为分类 | 准确率+0.58% | 显著超越 |

**消融实验结论**：
- 移除LGSE（LLM引导语义提取）→ 性能显著下降
- 移除排序损失 → 重要性学习失效
- 移除SRR（语义关系推理）→ 复杂意图识别能力下降
- 三种语义关系（重要性、互补性、不一致性）均不可或缺

**vs 多模态大模型（MLLMs）**：
- 冻结/微调后的Qwen2-VL、VideoLLaMA2等，性能均远低于LGSRR
- 原因：MLLMs缺乏对细粒度语义关系的显式建模

#### 2.3.6 LGSRR与现有方法对比

| 维度 | 传统融合方法 | MLLMs直接推理 | LGSRR |
|------|-------------|--------------|-------|
| **语义粒度** | 粗粒度（模态级） | 中粒度（token级） | 细粒度（语义维度级） |
| **关系建模** | 简单融合（拼接/加权） | 隐式建模 | 显式逻辑关系（OR/AND/NOT） |
| **可解释性** | 低 | 中 | 高（语义排序可追溯） |
| **计算成本** | 低 | 极高 | 中（LLM仅用于离线监督） |
| **复杂意图** | 弱 | 中 | 强 |

> 📌 **启示**：LGSRR展示了"大模型引导小模型"的高效范式，对电商客服、智能导购等垂直领域的多模态意图理解具有重要应用前景。

#### 2.3.7 局限性与改进方向

- **局限**：未完全考虑语义关系的语境依赖性，数据稀疏类别表现有限
- **改进方向**：探索更具表达力的关系结构、自适应推理机制、上下文感知的动态权重

### 2.4 性能评估指标

| 指标 | 说明 |
|------|------|
| **Accuracy** | 整体正确率 |
| **Precision** | 预测为正的准确性 |
| **Recall** | 正样本的覆盖率 |
| **F1-score** | 平衡指标，常用于类别不均衡场景 |

---

## 三、整体架构设计

采用 **"五层架构+三线优化"** 设计：
- **五层架构**：数据层 → 特征层 → 核心识别层 → 应用层 → 运维监控层
- **三线优化**：延迟优化（轻量化、缓存、并行）→ 成本优化（分层资源、弹性调度）→ 精度优化（知识增强、时序建模）

### 3.1 系统架构图

```mermaid
graph TB
    subgraph 数据层
        A1[用户搜索Query]
        A2[点击/浏览行为]
        A3[加购/收藏行为]
        A4[客服对话记录]
        A5[用户画像数据]
    end
    
    subgraph 数据采集层
        B[实时数据采集]
        B1[流式处理引擎<br/>Flink/Storm]
        B2[数据清洗与标准化]
    end
    
    subgraph 意图理解与建模层[核心层]
        C1[Query理解模块<br/>Qwen-1.8B微调]
        C2[多模态意图融合<br/>LLM推理+Embedding]
        C3[用户状态建模<br/>状态机+LLM推理]
        C4[意图分类/聚类<br/>静态分类+动态发现]
        
        C1 --> C2
        C2 --> C3
        C3 --> C4
    end
    
    subgraph 服务层
        D[意图服务API<br/>统一接口]
        D1[意图Embedding服务]
        D2[结构化标签服务]
        D3[状态预测服务]
    end
    
    subgraph 应用层
        E1[搜索排序]
        E2[个性化推荐]
        E3[智能客服]
        E4[营销触发]
    end
    
    subgraph 离线训练层
        F1[Qwen-Max<br/>样本生成/难例解析]
        F2[模型蒸馏]
        F3[持续学习]
    end
    
    A1 & A2 & A3 & A4 & A5 --> B
    B --> B1
    B1 --> B2
    B2 --> C1
    B2 --> C2
    
    C4 --> D
    D --> D1 & D2 & D3
    D1 & D2 & D3 --> E1 & E2 & E3 & E4
    
    F1 --> C1
    F2 --> C1
    F3 --> C4
    
    E1 & E2 & E3 & E4 -.反馈数据.-> B
```

### 3.2 架构设计原则

1. **大模型定位**：大模型不下沉到端到端推荐，而是作为"语义理解中枢"，专注于意图理解与表示
2. **在线轻量、离线强大**：
   - **离线**：Qwen-Max用于样本生成/难例解析、模型蒸馏
   - **在线**：Qwen-1.8B蒸馏模型用于线上推理，保证低延迟
3. **闭环反馈**：用户行为 → 意图修正 → 效果验证 → 模型优化
4. **分层解耦**：数据层、理解层、服务层、应用层清晰分离，便于独立优化和扩展
5. **多模态融合**：统一处理文本、行为序列、上下文信息，形成综合意图表示

### 3.3 数据层设计

#### 3.3.1 数据类型与采集

| 数据类别 | 具体内容 | 采集方式 | 核心价值 |
|---------|---------|---------|---------|
| **多模态上下文** | 文本（搜索词、咨询话术）、图像（拍立淘图片、商品图）、音频（客服语音）、行为上下文 | 实时采集 + 异步补全 | 补充意图相关的实时信息 |
| **长用户行为** | 交易行为（近3年购买/退款）、浏览行为（近1年点击/停留）、偏好行为（价格敏感度、品牌偏好） | 离线批量 + 实时增量 | 锚定用户个性化特征 |
| **辅助数据** | 商品数据（类目、价格）、场景数据（大促/日常）、知识数据（电商术语词典） | 定时同步 + 实时更新 | 为LLM提供领域知识 |

#### 3.3.2 长行为数据分层存储

| 数据层级 | 数据范围 | 存储介质 | 检索延迟 | 存储成本 |
|---------|---------|---------|---------|---------|
| **热数据** | 近7天行为 | Redis集群 | ≤10ms | 0.5元/GB/月 |
| **温数据** | 7天-3个月行为 | Milvus + ClickHouse | ≤50ms | 0.1元/GB/月 |
| **冷数据** | 3个月以上行为 | OSS + Hive | ≤1s（离线） | 0.01元/GB/月 |

> **关键优化**：冷数据通过LLM生成结构化摘要（如"用户A：偏好300-500元女装，年购5次，价格敏感"），存储量降低99%。

#### 3.3.3 数据预处理策略

- **清洗过滤**：剔除无效数据（停留＜1秒的点击、重复咨询），文本去噪
- **标准化处理**：统一多模态数据格式（图像224×224、音频16kHz），行为数据标准化为"行为类型-时间-权重"三元组
- **隐私脱敏**：敏感信息脱敏，行为数据仅保留用户ID关联

### 3.4 特征层设计

#### 3.4.1 单模态特征提取（轻量化优先）

| 模态类型 | 模型选型 | 优化策略 | 特征维度 | 推理耗时 |
|---------|---------|---------|---------|---------|
| **文本** | MiniLM-L6（中文优化版） | 电商领域预训练 | 384维 | ≤15ms |
| **图像** | MobileNetV3 + CLIP-light | 知识蒸馏 | 512维 | ≤30ms |
| **音频** | Wav2Vec 2.0（轻量版） | 仅提取语义+情感特征 | 256维 | ≤50ms |
| **用户行为** | 因子机（FM）+ 时序注意力 | 时间衰减权重 | 384维 | ≤10ms |

#### 3.4.2 多模态特征融合与对齐

1. **特征级融合**：通过"跨模态注意力模块"将文本、图像、行为特征映射到统一语义空间，输出融合特征向量（768维）
2. **决策级融合**：单模态特征分别输入轻量分类器得到初步意图概率，与LLM精识别结果加权融合（LLM权重0.7，单模态权重0.3）
3. **对齐优化**：利用电商领域知识图谱引导多模态特征向意图语义对齐

#### 3.4.3 特征缓存策略

- **热门商品特征**：月销10万+商品的图像/文本特征预计算并缓存，命中率≥40%
- **高频用户特征**：活跃用户的行为特征实时更新并缓存
- **特征过期机制**：热门特征缓存1小时，普通特征缓存10分钟

---

## 四、核心模块详解

### 4.1 Query理解：结构化解析

#### 4.1.1 功能目标

将自然语言Query解析为标准结构化字段，包括：
- **用户身份**：学生党、上班族、宝妈等
- **品类**：连衣裙、耳机、手机等
- **属性**：价格区间、材质、风格、功能等
- **场景**：日常通勤、运动、送礼等
- **时间/季节**：夏季、冬季、节日等

#### 4.1.2 技术方案

**阶段一：零样本泛化（冷启动）**
- 使用 Few-shot Prompting + Qwen-Max 实现零样本泛化
- 无需训练即可处理新Query类型
- 支持快速迭代和验证

**阶段二：模型微调（性能优化）**
- 对高频Query，使用 Qwen-1.8B 微调模型
- 提升解析准确率与一致性
- 降低推理延迟和成本

#### 4.1.3 输出示例

```json
{
  "query": "适合小个子夏天通勤的平价连衣裙",
  "parsed_result": {
    "user_identity": "学生党",
    "category": "连衣裙",
    "attributes": ["平价", "透气", "碎花", "小个子"],
    "scene": "日常通勤",
    "season": "夏季",
    "price_range": "50-200",
    "confidence": 0.92
  },
  "embedding": [0.123, 0.456, ...]
}
```

#### 4.1.4 数据需求

- **初期**：5,000 条标注样本 + 大模型自动扩增
- **优化期**：20,000+ 条高质量样本用于微调

---

### 4.2 多模态意图融合

#### 4.2.1 输入数据

- **Query文本**：用户搜索词
- **行为序列**：最近N次点击商品（商品ID、类目、价格、属性）
- **上下文信息**：时间、设备、促销活动、地理位置

#### 4.2.2 融合方法

**步骤1：行为序列编码**
- 将商品序列编码为行为上下文向量（使用商品Embedding + 时间衰减）
- 提取行为模式特征（价格趋势、类目分布、浏览深度等）

**步骤2：LLM推理融合**
- 构造Prompt注入LLM进行意图推理
- 示例Prompt：

```
用户最近浏览了以下商品：
1. 商品A：AirPods Pro，价格1999元
2. 商品B：Beats Studio3，价格1899元
3. 商品C：Sony WH-1000XM4，价格2299元

当前搜索："性价比高的耳机"

请分析用户的真实意图，并输出：
- 意图标签（如：比价、高端降级、功能对比）
- 意图置信度
- 推荐策略建议
```

**步骤3：统一表示**
- 输出统一意图Embedding（768维向量）
- 生成可解释标签（结构化JSON）

#### 4.2.3 技术优势

- **解决意图冲突**：识别"嘴上说便宜，实际点高端"的真实意图
- **上下文感知**：结合历史行为，理解当前Query的真实含义
- **多模态理解**：统一处理文本、行为、上下文信息

#### 4.2.4 语义关系推理增强（基于LGSRR思想）

借鉴LGSRR框架，在多模态融合中引入 **语义关系推理模块**，建模三种逻辑关系：

```mermaid
graph TB
    subgraph 语义关系推理
        A[文本语义] --> D[互补性建模<br/>AND]
        B[行为语义] --> D
        C[图像语义] --> D
        
        A --> E[不一致性检测<br/>NOT]
        B --> E
        
        D --> F[重要性排序<br/>OR]
        E --> F
        
        F --> G[融合意图表示]
    end
```

| 关系类型 | 电商场景应用 | 实现方式 |
|---------|-------------|---------|
| **互补性（AND）** | 搜索词"便宜耳机" + 浏览高端商品 → 互补揭示"比价"意图 | 余弦相似度加权增强 |
| **不一致性（NOT）** | 文字说"随便看看" + 行为频繁加购 → 冲突揭示"购买"意图 | 均方误差正则化惩罚 |
| **重要性（OR）** | 近期行为 > 远期行为，购买行为 > 浏览行为 | NeuralNDCG排序学习 |

**LLM引导的语义维度发现**（Shallow-to-Deep CoT）：

```
【Step 1: 发现语义维度】
分析电商用户意图识别任务，归纳关键语义维度：
- 价格敏感度（搜索词中的价格词、浏览商品价格分布）
- 品牌偏好（历史购买品牌、搜索品牌词频率）
- 购买紧迫度（加购时间间隔、促销敏感度）
- 品类倾向（类目浏览深度、跨类目行为）

【Step 2: 生成语义描述】
针对用户A的当前会话，生成各维度描述：
- 价格敏感度：高（搜索词含"平价"，浏览商品均价<200元）
- 品牌偏好：中（无明确品牌词，但历史购买集中于3个品牌）
- 购买紧迫度：高（30分钟内加购3次，正值大促期间）

【Step 3: 重要性排序】
基于意图标签"比价购买"，排序各维度重要性：
1. 价格敏感度（权重0.4）
2. 购买紧迫度（权重0.3）
3. 品类倾向（权重0.2）
4. 品牌偏好（权重0.1）
```

> ✅ **效果提升**：引入语义关系推理后，复杂意图（如"犹豫比价""冲动购买"）识别F1提升15%+

---

### 4.3 用户状态建模

#### 4.3.1 状态定义

```mermaid
stateDiagram-v2
    [*] --> 浏览: 首次访问/搜索
    浏览 --> 比较: 点击多个商品
    比较 --> 犹豫: 加购未付/收藏
    犹豫 --> 决策: 查看评价/详情
    决策 --> 购买: 下单
    决策 --> 犹豫: 放弃购买
    购买 --> 售后: 收货后
    售后 --> [*]: 完成/退货
```

**状态说明**：
- **浏览**：初步探索，意图模糊
- **比较**：对比多个商品，意图明确但未决策
- **犹豫**：有购买意向但存在顾虑
- **决策**：即将购买，需要最后确认
- **售后**：已购买，关注使用体验

#### 4.3.2 实现方法

**方法1：规则初筛（快速路径）**
- 基于行为规则快速判断（如"加购未付"=犹豫）
- 覆盖80%常见场景，延迟<10ms

**方法2：LLM推理（复杂场景）**
- 对复杂会话叙事做推理，输出状态置信度
- 示例Prompt：

```
用户行为序列：
- 搜索："蓝牙耳机"
- 点击3款<200元商品
- 查看"7天无理由退货"政策
- 浏览商品评价（重点关注音质和续航）

请判断用户当前最可能处于哪个购物阶段？
输出：状态名称 + 置信度 + 关键行为证据
```

#### 4.3.3 应用场景

- **犹豫期**：推送优惠券、限时折扣
- **决策期**：展示详细对比、用户评价
- **浏览期**：提供个性化推荐、热门商品

---

### 4.4 三级漏斗意图识别模型

```mermaid
graph LR
    A[用户请求] --> B{一级漏斗<br/>规则引擎}
    B -->|高频简单意图<br/>40%分流| C[直接返回]
    B -->|中低频意图| D{二级漏斗<br/>轻量分类器}
    D -->|中频意图<br/>45%分流| E[返回Top3候选]
    D -->|复杂意图| F{三级漏斗<br/>LLM精识别}
    F -->|15%请求| G[深度推理返回]
```

#### 4.4.1 一级漏斗：规则引擎粗识别

针对高频简单意图（如"查物流""退差价""领优惠券"），实现"零LLM调用、毫秒级响应"：

- **关键词库**：维护电商领域500+核心意图关键词
- **场景规则**：结合上下文触发（如"订单号+'查物流'"直接识别为"物流查询意图"）
- **更新机制**：每周根据客服日志更新规则库
- **分流效果**：40%请求，延迟≤5ms

#### 4.4.2 二级漏斗：轻量分类器

采用"DistilBERT+随机森林"的混合模型，处理中频意图：

- **输入**：融合特征向量 + 用户长行为特征
- **输出**：Top3候选意图 + 置信度
- **优化**：基于用户长行为特征增强（如"历史多次比价用户"优先识别为"比价意图"）
- **性能**：准确率≥90%，推理耗时≤20ms，分流45%请求

#### 4.4.3 三级漏斗：LLM精识别

针对复杂意图（如"跨品类比价""售后问题复合咨询"），融合多模态特征与长行为摘要：

**LLM选型**：

| 意图复杂度 | LLM选型 | 优化手段 | 推理耗时 | 调用成本 |
|-----------|---------|---------|---------|---------|
| 一般复杂 | Qwen-1.8B（4bit量化） | 电商场景微调+RTP-LLM | ≤80ms | ≈0.001元/次 |
| 极复杂 | 通义千问-7B（云API） | Prompt精简+结果过滤 | ≤200ms | ≈0.01元/次 |

**淘宝场景定制Prompt**：

```
【淘宝用户意图识别任务】
已知信息：
1. 用户长行为摘要：{用户3个月内购买2次口红，偏好YSL品牌，点击过"比价"标签，价格敏感}
2. 当前多模态输入：
   - 文本："这个口红比YSL便宜吗？有没有优惠券？"
   - 图像：[口红商品图，类目=美妆-口红]
   - 行为上下文：刚加购YSL#1966口红
3. 候选意图：[比价购买，优惠券领取，品牌咨询]

任务：
1. 确定用户核心意图（从候选中选1个，或补充新意图）；
2. 提取关键参数（如商品类目、价格需求、品牌偏好）；
3. 输出格式：{"intent_type":"","parameters":{"":"","":""},"confidence":""}
```

**长行为融合策略**：
- **时序注意力**：LLM聚焦"近7天行为"，弱化远期行为影响
- **权重衰减**：近1天×1.0，近7天×0.8，近30天×0.5
- **摘要精简**：长行为压缩为100字以内的结构化摘要

---

### 4.5 意图分类与动态发现

#### 4.5.1 静态意图分类

**预定义意图体系**（50+意图类型）：
- **购买意图**：送礼、换新、比价、囤货、尝鲜
- **信息意图**：了解、对比、咨询
- **情感意图**：冲动购买、理性消费、品牌偏好

**技术实现**：
- 微调分类模型（基于Qwen-1.8B）
- 多标签分类，支持一个Query对应多个意图

#### 4.5.2 动态意图发现

**流程**：
1. **大规模聚类**：对1000万Query进行聚类
   - 使用Sentence-BERT生成Query Embedding
   - UMAP降维 + HDBSCAN聚类
2. **语义标签生成**：调用LLM为每个簇生成语义标签
   - 示例："露营装备入门需求"、"宠物用品新手购买"
3. **人工审核**：专家审核后纳入意图本体库
4. **持续更新**：定期（每周）发现新意图模式

**优势**：
- 自动发现新兴需求（如"露营经济"、"宠物经济"）
- 意图体系自进化，无需人工维护
- 适应市场变化和用户需求迁移

---

### 4.5 技术架构细节

#### 4.5.1 模型部署架构

```mermaid
graph TB
    subgraph 在线服务
        A[API网关] --> B[负载均衡]
        B --> C1[Query理解服务<br/>Qwen-1.8B]
        B --> C2[意图融合服务<br/>LLM推理]
        B --> C3[状态预测服务<br/>规则+LLM]
        
        C1 --> D[Redis缓存]
        C2 --> D
        C3 --> D
        
        D --> E[FeatureStore]
    end
    
    subgraph 离线训练
        F[训练数据] --> G[Qwen-Max<br/>样本生成]
        G --> H[模型蒸馏]
        H --> I[模型版本管理]
        I --> J[模型部署]
    end
    
    J --> C1 & C2 & C3
```

#### 4.5.2 数据流设计

- **实时流**：用户行为 → Kafka → Flink实时处理 → 意图服务
- **离线批处理**：历史数据 → Hive → 模型训练 → 模型更新
- **特征存储**：意图Embedding + 标签 → FeatureStore → 下游系统

---

## 五、大模型技术细节

### 5.1 模型选型与对比

#### 5.1.1 候选模型评估

| 模型 | 参数量 | 推理延迟 | 中文能力 | 适用场景 | 部署成本 |
|------|-------|---------|---------|---------|---------|
| **Qwen-Max** | 72B+ | 500ms+ | ⭐⭐⭐⭐⭐ | 离线标注、难例解析 | 高 |
| **Qwen-1.8B** | 1.8B | 20-30ms | ⭐⭐⭐⭐ | 在线推理（微调后） | 低 |
| **Qwen-7B** | 7B | 50-80ms | ⭐⭐⭐⭐⭐ | 平衡性能与成本 | 中 |
| **ChatGLM3-6B** | 6B | 40-60ms | ⭐⭐⭐⭐ | 对话场景 | 中 |
| **Llama3-8B** | 8B | 50-70ms | ⭐⭐⭐ | 通用场景 | 中 |

**推荐方案**：
- **在线服务**：Qwen-1.8B（经过领域微调 + INT8量化）
- **离线处理**：Qwen-Max（样本生成、复杂推理）
- **备选方案**：Qwen-7B（性能与成本平衡）

#### 5.1.2 模型架构设计（参考Meta DLRM）

```mermaid
graph TB
    subgraph 输入层
        A1[Query文本] --> B1[Text Encoder<br/>Qwen-1.8B]
        A2[用户ID] --> B2[User Embedding<br/>128维]
        A3[行为序列] --> B3[Behavior Encoder<br/>Transformer]
        A4[上下文特征] --> B4[Context MLP]
    end
    
    subgraph 特征交叉层
        B1 --> C[Cross Network<br/>特征交叉]
        B2 --> C
        B3 --> C
        B4 --> C
    end
    
    subgraph 意图输出层
        C --> D1[Intent Embedding<br/>768维]
        C --> D2[Intent Labels<br/>多标签分类]
        C --> D3[User State<br/>状态预测]
    end
    
    subgraph LLM重排序层[Meta风格]
        D1 --> E[LLM Reranker<br/>语义精排]
        D2 --> E
        E --> F[最终意图输出]
    end
```

### 5.2 Prompt工程

#### 5.2.1 Prompt设计原则

1. **结构化输出**：使用JSON Schema约束输出格式
2. **Few-shot示例**：提供3-5个高质量示例
3. **Chain-of-Thought**：复杂场景引导逐步推理
4. **角色设定**：明确模型的专家角色

#### 5.2.2 核心Prompt模板

**Query解析Prompt**：

```
你是淘宝电商领域的意图分析专家。请分析用户Query，提取结构化信息。

## 输出格式（严格JSON）
{
  "category": "商品品类",
  "attributes": ["属性1", "属性2"],
  "user_identity": "用户身份标签",
  "scene": "使用场景",
  "price_sensitivity": "high/medium/low",
  "purchase_urgency": "high/medium/low",
  "confidence": 0.0-1.0
}

## 示例
Query: "学生党平价蓝牙耳机推荐"
输出: {"category": "蓝牙耳机", "attributes": ["平价", "性价比"], "user_identity": "学生党", "scene": "日常使用", "price_sensitivity": "high", "purchase_urgency": "medium", "confidence": 0.95}

## 当前Query
Query: "{user_query}"
输出:
```

**多模态融合Prompt**：

```
你是用户意图分析专家。结合用户的搜索词和行为序列，推断真实购买意图。

## 用户行为上下文
- 搜索词：{query}
- 最近浏览：{browse_history}
- 加购商品：{cart_items}
- 价格区间：{price_range}

## 分析维度
1. 表面意图 vs 真实意图（是否存在"嘴上说便宜，实际点高端"）
2. 购物阶段（浏览/比较/犹豫/决策）
3. 决策因素（价格/品牌/功能/评价）

## 输出格式
{
  "surface_intent": "表面意图",
  "real_intent": "真实意图",
  "intent_gap": "意图差异说明",
  "shopping_stage": "购物阶段",
  "decision_factors": ["因素1", "因素2"],
  "recommendation_strategy": "推荐策略建议"
}
```

#### 5.2.3 Prompt优化技巧

| 技巧 | 说明 | 效果提升 |
|------|------|---------|
| **Self-Consistency** | 多次采样取众数 | 准确率+5% |
| **Constrained Decoding** | 限制输出token范围 | 格式正确率+20% |
| **Dynamic Few-shot** | 根据Query类型选择示例 | 准确率+8% |
| **Temperature调优** | 分类任务用低温度(0.1-0.3) | 稳定性+15% |

### 5.3 模型微调

#### 5.3.1 微调策略

**LoRA微调（推荐）**：

```python
# LoRA配置示例
lora_config = {
    "r": 64,                    # LoRA秩
    "lora_alpha": 128,          # 缩放因子
    "target_modules": [         # 目标模块
        "q_proj", "k_proj", "v_proj", "o_proj",
        "gate_proj", "up_proj", "down_proj"
    ],
    "lora_dropout": 0.05,
    "bias": "none",
    "task_type": "CAUSAL_LM"
}
```

**训练超参数**：

```yaml
training_args:
  learning_rate: 2e-4
  num_train_epochs: 3
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  bf16: true
  max_grad_norm: 1.0
```

#### 5.3.2 数据构造

**数据格式**：

```json
{
  "instruction": "分析以下电商Query的用户意图",
  "input": "适合小个子夏天通勤的平价连衣裙",
  "output": "{\"category\": \"连衣裙\", \"attributes\": [\"小个子\", \"夏季\", \"通勤\", \"平价\"], ...}"
}
```

**数据增强策略**：
1. **同义改写**：使用大模型生成Query变体
2. **属性组合**：随机组合属性生成新Query
3. **难例挖掘**：收集线上Bad Case重点标注
4. **对抗样本**：构造易混淆样本提升鲁棒性

### 5.4 知识蒸馏

#### 5.4.1 蒸馏流程

```mermaid
graph LR
    A[Qwen-Max<br/>教师模型] --> B[生成软标签<br/>概率分布]
    B --> C[构造蒸馏数据集]
    C --> D[Qwen-1.8B<br/>学生模型]
    D --> E[联合损失训练]
    E --> F[蒸馏后模型]
    
    subgraph 损失函数
        G[Hard Label Loss<br/>交叉熵]
        H[Soft Label Loss<br/>KL散度]
        I[Feature Loss<br/>隐层对齐]
    end
    
    E --> G
    E --> H
    E --> I
```

#### 5.4.2 蒸馏配置

```python
# 蒸馏损失函数
def distillation_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.7):
    """
    T: 温度参数，控制软标签平滑度
    alpha: 软标签损失权重
    """
    soft_loss = F.kl_div(
        F.log_softmax(student_logits / T, dim=-1),
        F.softmax(teacher_logits / T, dim=-1),
        reduction='batchmean'
    ) * (T * T)
    
    hard_loss = F.cross_entropy(student_logits, labels)
    
    return alpha * soft_loss + (1 - alpha) * hard_loss
```

#### 5.4.3 蒸馏效果对比

| 指标 | Qwen-Max | Qwen-1.8B原始 | Qwen-1.8B蒸馏后 |
|------|---------|--------------|----------------|
| Query解析准确率 | 95.2% | 78.3% | 91.8% |
| 意图分类F1 | 93.5% | 75.6% | 89.2% |
| 推理延迟(P99) | 520ms | 25ms | 28ms |
| 显存占用 | 140GB | 4GB | 4GB |

### 5.5 推理优化

#### 5.5.1 优化技术栈

| 技术 | 优化效果 | 适用场景 |
|------|---------|---------|
| **INT8量化** | 延迟-40%，显存-50% | 在线推理 |
| **KV Cache优化** | 长序列推理加速2x | 多轮对话 |
| **Flash Attention 2** | 显存-50%，速度+2x | 所有场景 |
| **Speculative Decoding** | 推理加速2-3x | 生成任务 |
| **Continuous Batching** | 吞吐提升3-5x | 高并发场景 |
| **PagedAttention (vLLM)** | 显存利用率+50% | 大规模部署 |

#### 5.5.2 部署架构

```mermaid
graph TB
    subgraph 推理服务集群
        A[Nginx负载均衡] --> B1[vLLM实例1<br/>GPU A100]
        A --> B2[vLLM实例2<br/>GPU A100]
        A --> B3[vLLM实例N<br/>GPU A100]
    end
    
    subgraph 缓存层
        C[Redis Cluster<br/>意图缓存]
        D[本地LRU Cache<br/>热点Query]
    end
    
    subgraph 降级策略
        E[规则引擎<br/>关键词匹配]
        F[轻量模型<br/>BERT分类]
    end
    
    B1 & B2 & B3 --> C
    C --> D
    B1 & B2 & B3 -.超时降级.-> E
    E -.二次降级.-> F
```

#### 5.5.3 性能基准

| 配置 | QPS | P50延迟 | P99延迟 | GPU利用率 |
|------|-----|--------|--------|----------|
| Qwen-1.8B + FP16 | 200 | 35ms | 80ms | 70% |
| Qwen-1.8B + INT8 | 350 | 22ms | 50ms | 85% |
| Qwen-1.8B + vLLM + INT8 | 800 | 15ms | 35ms | 92% |
| + Redis缓存(命中率60%) | 2000 | 5ms | 30ms | 60% |

### 5.6 在线学习与实时更新（参考字节Monolith）

#### 5.6.1 实时特征更新

```mermaid
graph LR
    A[用户行为流] --> B[Flink实时处理]
    B --> C[特征计算]
    C --> D[Feature Store<br/>实时更新]
    D --> E[意图服务<br/>实时特征注入]
    
    F[模型参数] --> G[Parameter Server]
    G --> E
    
    H[在线学习] --> G
    B --> H
```

#### 5.6.2 增量学习策略

- **Embedding实时更新**：用户/商品Embedding每小时增量更新
- **模型定期微调**：每周使用新数据进行LoRA微调
- **A/B测试验证**：新模型灰度发布，验证效果后全量

---

## 六、数据与训练策略

### 6.1 数据需求与来源

| 模块 | 标注数据需求 | 数据来源 | 训练方式 | 备注 |
|------|-------------|---------|---------|------|
| Query解析 | 5k~20k 条 | 人工标注 + 客服日志 | 微调 + 蒸馏 | 初期少量样本即可启动 |
| 意图分类 | 10w~50w 条 | LLM自动打标 + 抽检 | 监督学习 | 利用大模型降低标注成本 |
| 状态建模 | 2w~5w 条 | 规则生成 + 人工校验 | 小样本微调 | 规则+LLM结合 |
| 多模态融合 | 无需显式标注 | 用户行为日志（弱监督） | 对比学习 / 行为预测 | 自监督学习 |

> ✅ **关键技巧**：利用淘宝海量日志构建弱监督信号，大幅降低标注成本。

### 6.2 训练流程

```mermaid
graph LR
    A[原始数据] --> B[数据清洗]
    B --> C[LLM自动标注]
    C --> D[人工抽检]
    D --> E[高质量数据集]
    E --> F[模型训练]
    F --> G[模型评估]
    G --> H{性能达标?}
    H -->|是| I[模型蒸馏]
    H -->|否| J[数据增强]
    J --> E
    I --> K[模型部署]
    K --> L[线上监控]
    L --> M[效果反馈]
    M --> A
```

### 6.3 模型优化策略

1. **知识蒸馏**：Qwen-Max → Qwen-1.8B，保持性能的同时降低延迟
2. **持续学习**：定期用新数据微调，适应意图变化
3. **难例挖掘**：识别错误样本，用Qwen-Max重新标注

---

## 七、工程落地考量

### 7.1 性能指标

| 维度 | 目标 | 实现方案 |
|------|------|---------|
| **延迟** | 在线服务 < 50ms | 缓存（Redis）+ 轻量模型（Qwen-1.8B）+ 异步处理 |
| **吞吐** | QPS > 10,000 | 水平扩展 + 负载均衡 + 模型量化 |
| **准确率** | Query解析准确率 > 90% | 模型微调 + 持续优化 |
| **可用性** | 99.9% | 多副本部署 + 容灾机制 |

### 7.2 容灾与降级

**容灾策略**：
1. **大模型超时**：自动回退到规则引擎（关键词+类目树）
2. **服务异常**：返回默认意图（通用推荐）
3. **数据异常**：使用历史缓存数据

**降级方案**：

```mermaid
graph TD
    A[请求] --> B{服务正常?}
    B -->|是| C[LLM推理]
    B -->|否| D{缓存可用?}
    D -->|是| E[返回缓存结果]
    D -->|否| F[规则引擎]
    F --> G[返回基础意图]
    C --> H[更新缓存]
    H --> I[返回结果]
```

### 7.3 部署架构

**基础设施**：
- **平台**：阿里云百炼平台（大模型服务）+ EAS弹性服务（推理服务）
- **存储**：Redis（缓存）+ FeatureStore（特征存储）+ OSS（模型存储）
- **监控**：SLS日志 + ARMS监控 + 自定义指标

**部署流程**：
1. 模型训练完成 → 模型验证
2. 模型上传至OSS → 版本管理
3. EAS服务更新 → 灰度发布（10% → 50% → 100%）
4. 监控指标 → 效果评估 → 全量发布

### 7.4 特征输出

**输出格式**：
- **意图Embedding**：768维向量，写入FeatureStore
- **结构化标签**：JSON格式，包含意图类型、置信度、状态等
- **实时更新**：用户行为触发意图更新，实时写入

**下游应用**：
- 搜索排序：使用意图Embedding进行语义匹配
- 个性化推荐：结合意图标签进行精准推荐
- 智能客服：根据意图提供个性化话术
- 营销触发：基于用户状态触发营销策略

### 7.5 效果评估

**评估指标**：
- **业务指标**：CTR（点击率）、CVR（转化率）、GMV（成交额）提升
- **技术指标**：意图识别准确率、意图覆盖率、响应延迟

**评估方法**：
- **AB测试**：对比"有无意图引擎"下的效果差异
- **离线评估**：在测试集上评估模型性能
- **在线监控**：实时监控意图分布、异常情况

---

## 八、预期收益与演进

### 8.1 短期收益（3个月内）

| 指标 | 目标提升 | 衡量方式 |
|------|---------|---------|
| 长尾Query理解准确率 | +15%+ | 测试集准确率对比 |
| 模糊意图识别覆盖率 | +30% | 意图覆盖率统计 |
| 人工规则维护成本 | -50% | 规则数量减少 |
| 搜索CTR提升 | +5~10% | AB测试对比 |
| 推荐CVR提升 | +3~8% | AB测试对比 |

### 8.2 长期演进方向

#### 8.2.1 意图Agent化
- **主动澄清**：LLM主动发起澄清对话
  - 示例："您更看重续航还是音质？"
  - 根据用户回答动态调整意图理解
- **意图引导**：帮助用户明确需求，提升转化率

#### 8.2.2 端侧轻量化
- **实时感知**：App内实时感知意图变化
- **边缘计算**：将轻量模型部署到端侧，降低延迟
- **离线能力**：支持离线场景下的意图理解

#### 8.2.3 跨平台意图迁移
- **平台打通**：淘宝、天猫、闲鱼用户意图统一建模
- **跨域迁移**：利用迁移学习，快速适配新平台
- **意图共享**：构建统一的意图知识库

#### 8.2.4 多模态增强
- **图像理解**：结合商品图片理解用户意图
- **语音交互**：支持语音搜索的意图理解
- **视频理解**：理解用户浏览视频的行为意图

---

## 九、总结

本方案充分发挥大模型在语义理解、上下文推理、知识泛化上的优势，同时通过蒸馏、缓存、弱监督等工程手段保障线上稳定性与性能，实现了**"强语义 + 快响应 + 低运维"**的意图引擎架构。

### 核心优势

1. **技术先进性**：基于大模型的语义理解，突破传统关键词匹配的局限
2. **工程可行性**：通过模型蒸馏、缓存优化等手段，满足线上性能要求
3. **业务价值**：提升搜索推荐效果，降低运营成本
4. **可扩展性**：支持动态意图发现，适应业务变化

### 落地路径

| 阶段 | 时间 | 目标 |
|------|------|------|
| **Phase 1** | 1-2个月 | 完成Query理解模块，验证核心能力 |
| **Phase 2** | 2-3个月 | 完成多模态融合和状态建模，上线核心功能 |
| **Phase 3** | 3-6个月 | 完成意图动态发现，实现全量覆盖 |
| **Phase 4** | 6个月+ | 探索Agent化和跨平台能力 |

本方案具备在淘宝大规模落地的可行性，预期能够显著提升用户体验和业务效果。

---

## 附录

### A. 技术栈

| 类别 | 技术选型 |
|------|---------|
| **大模型** | Qwen-Max（离线）、Qwen-1.8B（在线） |
| **框架** | PyTorch、Transformers、PEFT（LoRA） |
| **推理引擎** | vLLM、TensorRT-LLM |
| **部署** | 阿里云百炼、EAS、Kubernetes |
| **存储** | Redis Cluster、FeatureStore、OSS |
| **流处理** | Flink、Kafka |
| **监控** | SLS、ARMS、Prometheus + Grafana |

### B. 参考资源

**业界实践**：
- [Meta Advantage+ 广告引擎](https://www.facebook.com/business/ads/advantage-plus)
- [Meta DLRM 推荐模型](https://github.com/facebookresearch/dlrm)
- [字节 Monolith 实时推荐系统](https://arxiv.org/abs/2209.07663)

**技术论文**：
- [Qwen模型文档](https://github.com/QwenLM/Qwen)
- [Sentence-BERT论文](https://arxiv.org/abs/1908.10084)
- [UMAP降维算法](https://umap-learn.readthedocs.io/)
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)
- [vLLM: PagedAttention](https://arxiv.org/abs/2309.06180)
- [Flash Attention 2](https://arxiv.org/abs/2307.08691)

**多模态意图识别**：
- [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/pdf/2507.22934) - 多模态意图识别综述
- [LGSRR: LLM-Guided Semantic Relational Reasoning for MIR](https://arxiv.org/pdf/2509.01337) - LLM引导的语义关系推理框架
- [LGSRR开源代码](https://github.com/thuiar/LGSRR)

### C. 与Meta Advantage+的对比

| 维度 | Meta Advantage+ | 本方案 |
|------|----------------|--------|
| **核心技术** | LLM重排序 + Gen AI创意 | LLM意图理解 + 蒸馏部署 |
| **模型规模** | 大模型在线推理 | 大模型离线 + 小模型在线 |
| **业务场景** | 广告投放优化 | 搜索推荐意图理解 |
| **实时性** | 准实时（秒级） | 实时（毫秒级） |
| **差异化** | 创意生成能力 | 电商领域深度定制 |
